% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/p_logreg_xerrors.R
\name{p.logreg.xerrors}
\alias{p.logreg.xerrors}
\title{Poolwise Logistic Regression with Errors in Continuous Exposure Variable}
\usage{
p.logreg.xerrors(g, y, xtilde, c = NULL, error.type = "both",
  diff.pe = FALSE, diff.me = FALSE, constant.pe = TRUE, p_y1 = NULL,
  p_sample.y1y0 = NULL, approx.integral = TRUE, integrate.tol = 1e-08,
  integrate.tol.start = integrate.tol,
  integrate.tol.hessian = integrate.tol, estimate.var = FALSE, ...)
}
\arguments{
\item{g}{Numeric vector of pool sizes (number of individuals in each pool).}

\item{y}{Numeric vector with poolwise \code{Y} values, coded 0 if all members
are controls and 1 if all members are cases.}

\item{xtilde}{Numeric vector (or list of numeric vectors, if some pools have
replicates) with \code{Xtilde} values.}

\item{c}{Numeric matrix with poolwise \strong{\code{C}} values, if any.}

\item{error.type}{Character string specifying the errors that \code{X} is
subject to.  Possible values are \code{"neither"} for neither processing
error nor measurement error, \code{"processing"} for processing error only,
\code{"measurement"} for measurement error only, and \code{"both"} for both.}

\item{diff.pe, diff.me}{If \code{TRUE}, the processing (measurement) error
variance is allowed to be different for case pools vs. control pools.}

\item{constant.pe}{If \code{TRUE}, the processing error variance is assumed
to be constant with pool size; if \code{FALSE}, it is assumed to increase
with pool size such that, for example, the processing error affecting a pool
twice as large as another will have twice the variance.}

\item{p_y1}{Optional numeric value specifying disease prevalence, allowing
for valid estimation of the intercept with case-control sampling.  If it's
easier, you can specify \code{p_sample_y1y0} instead.  Only used if
\code{offset.formula = 1}.}

\item{p_sample.y1y0}{Optional numeric vector if length 2 specifying sampling
probabilities for cases and controls, allowing for valid estimation of the
intercept with case-control sampling.  If it's easier, you can specify
\code{p_y1} instead.}

\item{approx.integral}{If \code{TRUE}, probit approximation for the
logistic-normal integral is used to avoid numerically integrating \code{X}'s
out of the likelihood function.}

\item{integrate.tol}{Numeric value specifying the \code{tol} input to
\code{\link{adaptIntegrate}}.  Only used if \code{approx.integral = FALSE}.}

\item{integrate.tol.start}{Same as \code{integrate.tol}, but applies only to
the very first iteration of ML maximization.  The first iteration tends to
take much longer than subsequent ones, so less precise integration at the
start can speed things up.}

\item{integrate.tol.hessian}{Same as \code{integrate.tol}, but for use when
estimating the Hessian matrix only.  Sometimes more precise integration
(i.e. smaller tolerance) than used for maximizing the likelihood helps
prevent cases where the inverse Hessian is not positive definite.}

\item{estimate.var}{If \code{TRUE}, function returns variance-covariance
matrix for parameter estimates, calculated as the inverse of the estimated
Hessian matrix at the MLE's.}

\item{...}{Additional arguments to pass to \code{\link[stats]{nlminb}}
function for maximizing the log-likelihood function.}
}
\value{
A list containing the following:
\enumerate{
  \item Numeric vector of parameter estimates.
  \item Variance-covariance matrix (if \code{estimate.var = TRUE}).
  \item The returned \code{\link[stats]{nlminb}} object from maximizing the
log-likelihood function.
  \item Akaike information criterion (AIC).
}
}
\description{
Assumes normal linear model for exposure given covariates, and additive
normal processing errors and measurement errors acting on the poolwise mean
exposure. Borrows ideas from [1-3]. Manuscript fully describing the approach
is currently under review.
}
\references{
1. Schisterman, E.F., Vexler, A., Mumford, S.L. and Perkins, N.J.
(2010) "Hybrid Pooled-Unpooled Design for Cost-Efficient Measurement of
Biomarkers." \emph{Stat. Med.} \strong{29}(5): 597--613.

2. Lyles, R.H., Van Domelen, D.R., Mitchell, E.M. and
Schisterman, E.F. (2015) "A Discriminant Function Approach to Adjust for
Processing and Measurement Error When a Biomarker is Assayed in Pooled
Samples."
\emph{Int. J. Environ. Res. Public Health} \strong{12}(11): 14723--14740.

3. Weinberg, C.R. and Umbach, D.M. (1999) "Using Pooled Exposure
Assessment to Improve Efficiency in Case-Control Studies."
\emph{Biometrics} \strong{55}: 718--726.

Acknowledgment: This material is based upon work supported by the
National Science Foundation Graduate Research Fellowship under Grant No.
DGE-0940903.
}
