# Feb. 20, 2018

# Dane Van Domelen
# R code for paper on logistic regression w/ additive errors in X

# Clear workspace and load packages
rm(list = ls())
library("pooling")

# Power of two-sample t-test
(power.trad <- power.t.test(n = 25, delta = 0.5, sd = 1))
(power.pooled <- power.t.test(n = 25, delta = 0.5, sd = sqrt(1/3)))

# Load CPP data
setwd("C:/Users/Dane/Google Drive/Documents/Research/Dissertation/cpp_data")
load("cpp_df.rda")
load("mcp1_reps.rda")
load("c_list.rda")
setwd("C:/Users/Dane/Google Drive/Documents/Research/Dissertation/paper2/analysis")

# Look at missing count for each variable
apply(cpp.df, 2, function(x) sum(is.na(x)))

# Exclude pools with missing mcp1, m_age, nw, smoke, or SA
table(cpp.df$g)
locs <- ! is.na(cpp.df$mcp1) & ! is.na(cpp.df$m_age) & ! is.na(cpp.df$nw) &
  ! is.na(cpp.df$smoke) & ! is.na(cpp.df$SA) &
  sapply(c.list, function(x) sum(is.na(x))) == 0
cpp.df <- subset(cpp.df, subset = locs)
mcp1.reps <- mcp1.reps[locs]
c.list <- c.list[locs]
table(cpp.df$g)

# Look at range of MCP-1 values in pools of size 1
range(cpp.df$mcp1[cpp.df$g == 1])

# Calculate MCP-1 times 10 to get more meaningful OR's
cpp.df$mcp1_10x <- cpp.df$mcp1 * 10

# Marginal associations between covariates and SA
fit1 <- p_logreg(g = cpp.df$g,
                 y = cpp.df$SA_onezero,
                 x = cpp.df$mcp1)
fit1
paste(sprintf("%.3f", fit1$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(fit1$glm.var[2, 2])), ")", sep = "")

fit2 <- p_logreg(g = cpp.df$g,
                 y = cpp.df$SA_onezero,
                 x = cpp.df$m_age)
paste(sprintf("%.3f", fit2$theta.hat[2]), " (",
              sprintf("%.3f", sqrt(fit2$glm.var[2, 2])), ")", sep = "")

fit3 <- p_logreg(g = cpp.df$g,
                 y = cpp.df$SA_onezero,
                 x = cpp.df$nw)
paste(sprintf("%.3f", fit3$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(fit3$glm.var[2, 2])), ")", sep = "")

fit4 <- p_logreg(g = cpp.df$g,
                 y = cpp.df$SA_onezero,
                 x = cpp.df$smoke)
paste(sprintf("%.3f", fit4$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(fit4$glm.var[2, 2])), ")", sep = "")

fit5 <- p_logreg(g = cpp.df$g,
                 y = cpp.df$SA_onezero,
                 x = cpp.df[, c("mcp1", "m_age", "nw", "smoke")])
paste(sprintf("%.3f", fit5$theta.hat[-1]), " (",
      sprintf("%.3f", sqrt(diag(fit5$glm.var))[-1]), ")", sep = "")


# Table 1 -----------------------------------------------------------------

# Randomly sample 30 replicates to include in analysis.
k <- sapply(mcp1.reps, length)
table(k)
which.k2 <- which(k == 2)
set.seed(123)
locs.keepreps <- sample(which.k2, 30, replace = FALSE)
#locs.keepreps <- sample(which.k2, 121, replace = FALSE)
mcp1.reps2 <- list()
for (ii in 1: length(k)) {
  if (k[ii] == 1) {
    mcp1.reps2[[ii]] <- mcp1.reps[[ii]]
  } else {
    if (ii %in% locs.keepreps) {
      mcp1.reps2[[ii]] <- mcp1.reps[[ii]]
    } else {
      mcp1.reps2[[ii]] <- mcp1.reps[[ii]][1]
    }
  }
}
k <- sapply(mcp1.reps2, length)
table(k)
mcp1_10x.reps <- lapply(mcp1.reps2, function(x) x * 10)

# # Remove 6 outlier singles
# par(mfrow = c(1, 2))
# hist(cpp.df$mcp1_10x[cpp.df$g == 1], breaks = 50,
#      main = "MCP-1 for g = 1", xlab = "MCP-1")
# hist(cpp.df$mcp1_10x[cpp.df$g == 2], breaks = 50,
#      main = "MCP-1 for g = 2", xlab = "MCP-1")
# cpp.df.safety <- cpp.df
# locs <- which(cpp.df$g == 1 & cpp.df$mcp1_10x > 4)
# cpp.df <- cpp.df[-locs, ]
# mcp1_10x.reps <- mcp1_10x.reps[-locs]

# # Remove singles > 4 and doubles > 20
# par(mfrow = c(1, 2))
# hist(cpp.df$mcp1_10x[cpp.df$g == 1], breaks = 50,
#      main = "MCP-1 for g = 1", xlab = "MCP-1")
# hist(cpp.df$mcp1_10x[cpp.df$g == 2], breaks = 50,
#      main = "MCP-1 for g = 2", xlab = "MCP-1")
# cpp.df.safety <- cpp.df
# locs <- which((cpp.df$g == 1 & cpp.df$mcp1_10x > 4) | (cpp.df$g == 2 & cpp.df$mcp1_10x > 20))
# cpp.df <- cpp.df[-locs, ]
# mcp1_10x.reps <- mcp1_10x.reps[-locs]


# No replicates, neither error
lrf.n <- p_logreg_xerrors(g = cpp.df$g,
                          y = cpp.df$SA_onezero,
                          xtilde = cpp.df$mcp1_10x,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          errors = "neither",
                          estimate.var = TRUE,
                          lower = c(rep(-Inf, 9), 1e-3),
                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lrf.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lrf.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", lrf.n$aic), sep = "")

dfa.n <- p_dfa_xerrors(g = cpp.df$g,
                       y = cpp.df$SA,
                       xtilde = cpp.df$mcp1_10x,
                       c = cpp.df[, c("m_age", "nw", "smoke")],
                       errors = "neither",
                       lower = c(rep(-Inf, 5), 1e-3),
                       control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", dfa.n$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(dfa.n$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", dfa.n$aic), sep = "")

# No replicates, PE only
start <- c(rep(0, 9), rep(1, 2)) + rnorm(n = 11, sd = 0.1)
lrf.p <- p_logreg_xerrors(g = cpp.df$g,
                          y = cpp.df$SA_onezero,
                          xtilde = cpp.df$mcp1_10x,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          errors = "processing",
                          approx.integral = FALSE,
                          estimate.var = TRUE,
                          lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lrf.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lrf.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lrf.p$aic), sep = "")

lra.p <- p_logreg_xerrors(g = cpp.df$g,
                          y = cpp.df$SA_onezero,
                          xtilde = cpp.df$mcp1_10x,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          errors = "processing",
                          approx.integral = TRUE,
                          estimate.var = TRUE,
                          lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                          start = start,
                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.p$aic), sep = "")

dfa.p <- p_dfa_xerrors(g = cpp.df$g,
                       y = cpp.df$SA,
                       xtilde = cpp.df$mcp1_10x,
                       c = cpp.df[, c("m_age", "nw", "smoke")],
                       errors = "processing",
                       lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                       control = list(trace = 1, rel.tol = 1e-9))
dfa.p$estimates
paste(sprintf("%.3f", dfa.p$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(dfa.p$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", dfa.p$aic), sep = "")

# No replicates, ME only
start <- c(rep(0, 9), rep(1, 2))
lrf.m <- p_logreg_xerrors(g = cpp.df$g,
                          y = cpp.df$SA_onezero,
                          xtilde = cpp.df$mcp1_10x,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          errors = "measurement",
                          approx.integral = FALSE,
                          integrate.tol = 1e-11,
                          estimate.var = TRUE,
                          lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                          start = start,
                          control = list(trace = 1, rel.tol = 1e-9))
eigen(lrf.m$theta.var)
paste(sprintf("%.3f", lrf.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lrf.m$theta.var[2, 2])), "), ",
      sprintf("%.2f", lrf.m$aic), sep = "")

lra.m <- p_logreg_xerrors(g = cpp.df$g,
                          y = cpp.df$SA_onezero,
                          xtilde = cpp.df$mcp1_10x,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          errors = "measurement",
                          approx.integral = TRUE,
                          estimate.var = TRUE,
                          lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                          start = start,
                          control = list(trace = 1, rel.tol = 1e-9))
eigen(lra.m$theta.var)
paste(sprintf("%.3f", lra.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.m$theta.var[2, 2])), "), ",
      sprintf("%.2f", lra.m$aic), sep = "")

mat <- matrix(NA, ncol = 5, nrow = 100)
set.seed(1)
for (ii in 1: 100) {
  start <- c(rep(0, 9), rep(1, 2)) + rnorm(n = 11, sd = 0.1)
  lra.m <- p_logreg_xerrors(g = cpp.df$g,
                            y = cpp.df$SA_onezero,
                            xtilde = cpp.df$mcp1_10x,
                            c = cpp.df[, c("m_age", "nw", "smoke")],
                            errors = "measurement",
                            approx.integral = TRUE,
                            estimate.var = TRUE,
                            lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                            start = start,
                            control = list(trace = 0, rel.tol = 1e-9))
  mat[ii, ] <- c(lra.m$nlminb.object$objective, lra.m$aic, lra.m$theta.hat[2],
                 sqrt(lra.m$theta.var[2, 2]), lra.m$theta.hat["sigsq_x.c"])
}
range(mat[, 3])
range(mat[, 1])
range(mat[, 2])

start <- c(rep(0, 5), rep(1, 2))
dfa.m <- p_dfa_xerrors(g = cpp.df$g,
                        y = cpp.df$SA,
                        xtilde = cpp.df$mcp1_10x,
                        c = cpp.df[, c("m_age", "nw", "smoke")],
                        errors = "measurement",
                        lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                        start = start,
                        control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", dfa.m$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(dfa.m$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", dfa.m$aic), sep = "")

mat <- matrix(NA, ncol = 6, nrow = 10)
set.seed(1)
for (ii in 1: 10) {
  start <- c(rep(0, 5), rep(1, 2)) + rnorm(n = 7, sd = 0.1)
  dfa.m <- p_dfa_xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = cpp.df$mcp1_10x,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         errors = "measurement",
                         lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                         start = start,
                         control = list(trace = 1, rel.tol = 1e-9))
  mat[ii, ] <- c(dfa.m$estimates["logOR_adj.hat"], sqrt(dfa.m$estimates["logOR_adj.var"]),
                 dfa.m$estimates["logOR.hat"], sqrt(dfa.m$estimates["logOR.var"]),
                 dfa.m$nlminb.object$objective, dfa.m$aic)
}
mat


# Replicates, ME only
start <- c(rep(0, 9), rep(1, 2))
start <- c(rep(0, 9), rep(1, 2)) + rnorm(n = 11, sd = 0.1)
lrf.m2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           errors = "measurement",
                           approx.integral = FALSE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
eigen(lrf.m2$theta.var)
paste(sprintf("%.3f", lrf.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lrf.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lrf.m2$aic), sep = "")

start <- c(rep(0, 9), rep(1, 2))
start <- c(rep(0, 9), rep(1, 2)) + rnorm(n = 11, sd = 0.1)
lra.m2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "measurement",
                           approx.integral = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                           start = start,
                           estimate.var = TRUE,
                           control = list(trace = 1, rel.tol = 1e-9))
eigen(lra.m2$theta.var)
paste(sprintf("%.3f", lra.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.m2$aic), sep = "")

start <- c(rep(0, 5), rep(1, 2))
start <- c(rep(0, 5), rep(1, 2)) + rnorm(n = 7, sd = 0.1)
dfa.m2 <- p.disc.xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = mcp1_10x.reps,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         error.type = "measurement",
                         lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                         start = start,
                         control = list(trace = 1, rel.tol = 1e-9))
dfa.m2$estimates
paste(sprintf("%.3f", dfa.m2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(dfa.m2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", dfa.m2$aic), sep = "")

# Replicates, both
start <- c(rep(0, 9), rep(1, 3))
start <- c(rep(0, 9), rep(1, 3)) + rnorm(n = 12, sd = 0.1)
lrf.b2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           approx.integral = FALSE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
lrf.b2$theta.hat
eigen(lrf.b2$theta.var)
paste(sprintf("%.3f", lrf.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lrf.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lrf.b2$aic), sep = "")

start <- c(rep(0, 9), rep(1, 3))
start <- c(rep(0, 9), rep(1, 3)) + rnorm(n = 12, sd = 0.1)
lra.b2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           approx.integral = TRUE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
eigen(lra.b2$theta.var)
paste(sprintf("%.3f", lra.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.b2$aic), sep = "")

start <- c(rep(0, 5), rep(1, 3))
start <- c(rep(0, 5), rep(1, 3)) + rnorm(n = 8, sd = 0.1)
dfa.b2 <- p.disc.xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = mcp1_10x.reps,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         error.type = "both",
                         lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                         start = start,
                         control = list(trace = 1, rel.tol = 1e-9))
dfa.b2$estimates
paste(sprintf("%.3f", dfa.b2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(dfa.b2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", dfa.b2$aic), sep = "")

# Differential errors
start <- c(rep(0, 9), rep(1, 2))
lra.m2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "measurement",
                           diff.me = FALSE,
                           approx.integral = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                           start = start,
                           estimate.var = TRUE,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.m2$aic), sep = "")

start <- c(rep(0, 9), rep(1, 3))
lra.m3 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "measurement",
                           diff.me = TRUE,
                           approx.integral = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                           start = start,
                           estimate.var = TRUE,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.m3$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.m3$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.m3$aic), sep = "")

start <- c(rep(0, 9), rep(1, 3))
lra.b2 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           diff.pe = FALSE,
                           diff.me = FALSE,
                           approx.integral = TRUE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.b2$aic), sep = "")

start <- c(rep(0, 9), rep(1, 4))
lra.b3 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           diff.pe = TRUE,
                           diff.me = FALSE,
                           approx.integral = TRUE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 4)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.b3$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.b3$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.b3$aic), sep = "")

start <- c(rep(0, 9), rep(1, 4))
lra.b4 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           diff.pe = FALSE,
                           diff.me = TRUE,
                           approx.integral = TRUE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 4)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.b4$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.b4$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.b4$aic), sep = "")

start <- c(rep(0, 9), rep(1, 5))
lra.b5 <- p.logreg.xerrors(g = cpp.df$g,
                           y = cpp.df$SA_onezero,
                           xtilde = mcp1_10x.reps,
                           c = cpp.df[, c("m_age", "nw", "smoke")],
                           error.type = "both",
                           diff.pe = TRUE,
                           diff.me = TRUE,
                           approx.integral = TRUE,
                           estimate.var = TRUE,
                           lower = c(rep(-Inf, 9), rep(1e-3, 5)),
                           start = start,
                           control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lra.b5$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lra.b5$theta.var[2, 2])), "), ",
      sprintf("%.1f", lra.b5$aic), sep = "")

# Correlation between replicates
k <- sapply(mcp1_10x.reps, length)
table(k)
mcp1_10x.reps2 <- mcp1_10x.reps[k == 2]
rep1 <- sapply(mcp1_10x.reps2, function(x) x[1])
rep2 <- sapply(mcp1_10x.reps2, function(x) x[2])
plot(rep1, rep2)
points(c(-10, 10), c(-10, 10), type = "l", col = "blue")
cor.test(rep1, rep2)
cor.test(rep1, rep2, method = "spearman")


# Table 2 -----------------------------------------------------------------

fit.table2a <- p.logreg(g = cpp.df$g,
                        y = cpp.df$SA_onezero,
                        x = cpp.df[, c("mcp1_10x", "m_age", "nw", "smoke")],
                        method = "glm")
log_ors <- fit.table2a$theta.hat
ors <- exp(log_ors)
ses <- sqrt(diag(fit.table2a$glm.var))
t2a.beta_se <- paste(sprintf("%.3f", log_ors), " (",
                    sprintf("%.3f", ses), ")", sep = "")
t2a.or_ci <- paste(sprintf("%.3f", ors), " (",
                   sprintf("%.3f", exp(log_ors - 1.96 * ses)), ", ",
                   sprintf("%.3f", exp(log_ors + 1.96 * ses)), ")", sep = "")
t2a.p <- pnorm(q = -abs(log_ors / ses)) * 2
t2a.p <- summary(fit.table2a$glm.fit)

log_ors <- lrf.b2$theta.hat
ors <- exp(log_ors)
ses <- sqrt(diag(lrf.b2$theta.var))
t2b.beta_se <- paste(sprintf("%.3f", log_ors), " (",
                     sprintf("%.3f", ses), ")", sep = "")
t2b.or_ci <- paste(sprintf("%.3f", ors), " (",
                   sprintf("%.3f", exp(log_ors - 1.96 * ses)), ", ",
                   sprintf("%.3f", exp(log_ors + 1.96 * ses)), ")", sep = "")
t2b.p <- pnorm(q = -abs(log_ors / ses)) * 2

# Justification for using approximate ML - not really useful.
gvals <- 1: 5
lowerbound <- 0.1^2 * gvals * 1.58 / 1.7^2
plot(gvals, lowerbound)
lowerbound
sqrt(1 + lowerbound)

exact <- 0.2^2 * (gvals - gvals^2 * 1.58^2 / (gvals * 1.58 + gvals^2 * 2)) / 1.7^2
exact
sqrt(1 + exact)


# Table 3 -----------------------------------------------------------------

# Get parameters for simulation
m_age.all <- c(cpp.df$m_age1, cpp.df$m_age2)
age.table <- table(m_age.all)
(age.vals <- as.numeric(names(age.table)))
(age.probs <- prop.table(age.table))

nw_all <- c(cpp.df$nw1, cpp.df$nw2)
(p_nw <- round(mean(nw_all, na.rm = TRUE), 2))

smoke_all <- c(cpp.df$smoke1, cpp.df$smoke2)
(p_smoke <- round(mean(smoke_all, na.rm = TRUE), 2))

lr.full.b2$theta.hat
(betas <- round(lr.full.b2$theta.hat[1: 5], 2))
betas[2] <- 0.2
(alphas <- round(lr.full.b2$theta.hat[6: 9], 2))
(sigsq_x <- round(lr.full.b2$theta.hat[10], 2))
(sigsq_p <- round(lr.full.b2$theta.hat[11], 2))
(sigsq_m <- round(lr.full.b2$theta.hat[12], 2))

theta <- c(betas, alphas, sigsq_x, sigsq_p, sigsq_m)

# Load data from cluster
load("table3_betas.rda")
load("table3_ses.rda")
load("table3r_betas.rda")
load("table3r_ses.rda")

# PE only
lrt.betas <- table3.betas[[1]][[1]]
lrn.betas <- table3.betas[[1]][[2]]
lrf.betas <- table3.betas[[1]][[3]]
lra.betas <- table3.betas[[1]][[4]]
dfat.betas <- table3.betas[[1]][[5]]
dfan.betas <- table3.betas[[1]][[6]]
dfa.betas <- table3.betas[[1]][[7]]

plot(lrf.betas[, 2], lra.betas[, 2])
cor(lrf.betas[, 2], lra.betas[, 2])
max(abs(lrf.betas[, 2] - lra.betas[, 2]))

x <- dfa.betas[, 8]
y <- dfa.betas[, 10] / dfa.betas[, 8]
fit <- lm(y ~ x)
summary(fit)

plot(x, y,
     main = "Table 3 - PE only",
     ylab = "Bias-adjusted log-OR / MLE",
     xlab = "MLE")
abline(fit, col = "blue")


lrt.ses <- table3.ses[[1]][[1]]
lrn.ses <- table3.ses[[1]][[2]]
lrf.ses <- table3.ses[[1]][[3]]
lra.ses <- table3.ses[[1]][[4]]
dfat.ses <- table3.ses[[1]][[5]]
dfan.ses <- table3.ses[[1]][[6]]
dfa.ses <- table3.ses[[1]][[7]]


table(lrn.ses[, 11])
table(lrf.ses[, 13])
table(lra.ses[, 13])
table(dfa.ses[, 3])

estimates <- cbind(lrn.betas[, 2], lrf.betas[, 2], lra.betas[, 2], dfa.betas[, 10])
#ses = cbind(lrn.ses[, 2], lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 2])
ses = cbind(lrn.ses[, 2], lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 1])
sumsim(estimates = estimates,
       ses = ses,
       truth = 0.2)

sum(sign(dfa.betas[, 8]) != sign(dfa.betas[, 10]))

sum(lrf.betas[, 10] == 0.001)
sum(lrf.betas[, 11] == 0.001)

sum(lra.betas[, 10] == 0.001)
sum(lra.betas[, 11] == 0.001)

sum(dfa.betas[, 6] == 0.001)
sum(dfa.betas[, 7] == 0.001)

# ME only without replicates
lrt.betas <- table3.betas[[2]][[1]]
lrn.betas <- table3.betas[[2]][[2]]
lrf.betas <- table3.betas[[2]][[3]]
lra.betas <- table3.betas[[2]][[4]]
dfat.betas <- table3.betas[[2]][[5]]
dfan.betas <- table3.betas[[2]][[6]]
dfa.betas <- table3.betas[[2]][[7]]

plot(lrf.betas[, 2], lra.betas[, 2])
cor(lrf.betas[, 2], lra.betas[, 2])
max(abs(lrf.betas[, 2] - lra.betas[, 2]))

plot(lra.betas[, 2], dfa.betas[, 10])

x <- dfa.betas[, 8]
y <- dfa.betas[, 10] / dfa.betas[, 8]
fit <- lm(y ~ x)
summary(fit)

plot(x, y,
     main = "Table 3 - ME only w/o replicates",
     ylab = "Bias-adjusted log-OR / MLE",
     xlab = "MLE")
abline(fit, col = "blue")

lrt.ses <- table3.ses[[2]][[1]]
lrn.ses <- table3.ses[[2]][[2]]
lrf.ses <- table3.ses[[2]][[3]]
lra.ses <- table3.ses[[2]][[4]]
dfat.ses <- table3.ses[[2]][[5]]
dfan.ses <- table3.ses[[2]][[6]]
dfa.ses <- table3.ses[[2]][[7]]

table(lrn.ses[, 11])
table(lrf.ses[, 13])
table(lra.ses[, 13])
table(dfa.ses[, 3])

loc <- which(lrf.betas[, 2] > 2)
lra.betas[loc, ]
lrf.betas[loc, ]
dfa.betas[loc, ]

estimates <- cbind(lrn.betas[, 2], lrf.betas[, 2], lra.betas[, 2], dfa.betas[, 10])
#ses = cbind(lrn.ses[, 2], lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 2])
ses = cbind(lrn.ses[, 2], lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 1])
sumsim(estimates = estimates,
       ses = ses,
       truth = 0.2)

sum(lrf.betas[, 2] > 2)
sum(lra.betas[, 2] > 2)
locs <- which(lrf.betas[, 2] <= 2)

sumsim(estimates = estimates[locs, ],
       ses = ses[locs, ],
       truth = 0.2)

sum(sign(dfa.betas[, 8]) != sign(dfa.betas[, 10]))

mean(lrf.betas[locs, 10] == 0.001)
mean(lrf.betas[locs, 11] == 0.001)

mean(lra.betas[locs, 10] == 0.001)
mean(lra.betas[locs, 11] == 0.001)

mean(dfa.betas[locs, 6] == 0.001)
mean(dfa.betas[locs, 7] == 0.001)

# ME only with replicates
lrf.betas <- table3r.betas[[2]][[1]]
lra.betas <- table3r.betas[[2]][[2]]
dfa.betas <- table3r.betas[[2]][[3]]

plot(lrf.betas[, 2], lra.betas[, 2])
cor(lrf.betas[, 2], lra.betas[, 2])
max(abs(lrf.betas[, 2] - lra.betas[, 2]))

x <- dfa.betas[, 8]
y <- dfa.betas[, 10] / dfa.betas[, 8]
fit <- lm(y ~ x)
summary(fit)

plot(x, y,
     main = "Table 3 - ME only w/ replicates",
     ylab = "Bias-adjusted log-OR / MLE",
     xlab = "MLE")
abline(fit, col = "blue")

lrf.ses <- table3r.ses[[2]][[1]]
lra.ses <- table3r.ses[[2]][[2]]
dfa.ses <- table3r.ses[[2]][[3]]

table(lrf.ses[, 13])
table(lra.ses[, 13])
table(dfa.ses[, 3])

estimates <- cbind(lrf.betas[, 2], lra.betas[, 2], dfa.betas[, 10])
#ses = cbind(lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 1], dfa.ses[, 2])
ses = cbind(lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 1])
sumsim(estimates = estimates,
       ses = ses,
       truth = 0.2)

sum(sign(dfa.betas[, 8]) != sign(dfa.betas[, 10]))

mean(lrf.betas[, 10] == 0.001)
mean(lrf.betas[, 11] == 0.001)

mean(lra.betas[, 10] == 0.001)
mean(lra.betas[, 11] == 0.001)

mean(dfa.betas[, 6] == 0.001)
mean(dfa.betas[, 7] == 0.001)


# PE and ME without replicates
lrt.betas <- table3.betas[[3]][[1]]
lrn.betas <- table3.betas[[3]][[2]]
lrf.betas <- table3.betas[[3]][[3]]
lra.betas <- table3.betas[[3]][[4]]
dfat.betas <- table3.betas[[3]][[5]]
dfan.betas <- table3.betas[[3]][[6]]
dfa.betas <- table3.betas[[3]][[7]]

plot(lrf.betas[, 2], lra.betas[, 2])
plot(lrf.betas[, 2], lra.betas[, 2], xlim = c(-1, 1), ylim = c(-1, 1))
cor(lrf.betas[, 2], lra.betas[, 2])
max(abs(lrf.betas[, 2] - lra.betas[, 2]))

x <- dfa.betas[, 9]
y <- dfa.betas[, 11] / dfa.betas[, 9]
fit <- lm(y ~ x)
summary(fit)

plot(x, y,
     main = "Table 3 - PE and ME w/o replicates",
     ylab = "Bias-adjusted log-OR / MLE",
     xlab = "MLE")
abline(fit, col = "blue")

hist(lrf.betas[, 2])
hist(lra.betas[, 2])

mean(! inside(lrf.betas[, 2], c(-1, 1)))
mean(! inside(lra.betas[, 2], c(-1, 1)))
mean(! inside(dfa.betas[, 9], c(-1, 1)))

lrt.ses <- table3.ses[[3]][[1]]
lrn.ses <- table3.ses[[3]][[2]]
lrf.ses <- table3.ses[[3]][[3]]
lra.ses <- table3.ses[[3]][[4]]
dfat.ses <- table3.ses[[3]][[5]]
dfan.ses <- table3.ses[[3]][[6]]
dfa.ses <- table3.ses[[3]][[7]]

table(lrn.ses[, 11])
table(lrf.ses[, 13])
table(lra.ses[, 13])
table(dfa.ses[, 3])

estimates <- cbind(lrn.betas[, 2], lrf.betas[, 2], lra.betas[, 2], dfa.betas[, 9])
ses = cbind(lrn.ses[, 2], lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 1])
sumsim(estimates = estimates,
       ses = ses,
       truth = 0.2)
sumsim(estimates = estimates, ses = ses, truth = 0.2,
       statistics = c("median_bias", "iqr", "coverage"))

sprintf("%.3f", mean(lrn.betas[, 2]) - 0.2)
sprintf("%.3f", mean(lrf.betas[, 2]) - 0.2)
sprintf("%.3f", mean(lra.betas[, 2]) - 0.2)
sprintf("%.3f", mean(dfa.betas[, 8] - 0.2))
sprintf("%.3f", mean(dfa.betas[, 10] - 0.2))

sprintf("%.3f", median(lrt.betas[, 2]) - 0.2)
sprintf("%.3f", median(lrn.betas[, 2]) - 0.2)
sprintf("%.3f", median(lrf.betas[, 2]) - 0.2)
sprintf("%.3f", median(lra.betas[, 2]) - 0.2)
sprintf("%.3f", median(dfat.betas[, 9] - 0.2))
sprintf("%.3f", median(dfa.betas[, 9] - 0.2))
sprintf("%.3f", median(dfa.betas[, 11] - 0.2))

sprintf("%.3f", sd(lrn.betas[, 2]))
sprintf("%.3f", sd(lrf.betas[, 2]))
sprintf("%.3f", sd(lra.betas[, 2]))
sprintf("%.3f", sd(dfa.betas[, 9]))
sprintf("%.3f", sd(dfa.betas[, 11]))

sprintf("%.3f", IQR(lrt.betas[, 2]))
sprintf("%.3f", IQR(lrn.betas[, 2]))
sprintf("%.3f", IQR(lrf.betas[, 2]))
sprintf("%.3f", IQR(lra.betas[, 2]))
sprintf("%.3f", IQR(dfat.betas[, 9]))
sprintf("%.3f", IQR(dfa.betas[, 9]))
sprintf("%.3f", IQR(dfa.betas[, 11]))

zval <- abs(qnorm(0.025))

sprintf("%.3f", mean(lrt.betas[, 2] - zval * lrt.ses[, 2] < 0.2 &
                       lrt.betas[, 2] + zval * lrt.ses[, 2] > 0.2))

locs <- which(lrn.ses[, 11] == 1)
length(locs)
sprintf("%.3f", mean(lrn.betas[locs, 2] - zval * lrn.ses[locs, 2] < 0.2 &
                       lrn.betas[locs, 2] + zval * lrn.ses[locs, 2] > 0.2))

locs <- which(lrf.ses[, 13] == 1)
length(locs)
sprintf("%.3f", mean(lrf.betas[locs, 2] - zval * lrf.ses[locs, 2] < 0.2 &
                       lrf.betas[locs, 2] + zval * lrf.ses[locs, 2] > 0.2))

locs <- which(lra.ses[, 13] == 1)
length(locs)
sprintf("%.3f", mean(lra.betas[locs, 2] - zval * lra.ses[locs, 2] < 0.2 &
                       lra.betas[locs, 2] + zval * lra.ses[locs, 2] > 0.2))

sprintf("%.3f", mean(dfat.betas[, 9] - zval * dfat.ses[, 2] < 0.2 &
                       dfat.betas[, 9] + zval * dfat.ses[, 2] > 0.2))

locs <- which(dfa.ses[, 3] == 1)
length(locs) / nrow(dfa.ses)
sprintf("%.3f", mean(dfa.betas[locs, 9] - zval * dfa.ses[locs, 1] < 0.2 &
                       dfa.betas[locs, 9] + zval * dfa.ses[locs, 1] > 0.2))
sprintf("%.3f", mean(dfa.betas[locs, 11] - zval * dfa.ses[locs, 2] < 0.2 &
                       dfa.betas[locs, 11] + zval * dfa.ses[locs, 2] > 0.2))

sum(sign(dfa.betas[, 9]) != sign(dfa.betas[, 11]))
mean(sign(dfa.betas[, 9]) != sign(dfa.betas[, 11]))

mean(lrf.betas[, 10] == 0.001)
mean(lrf.betas[, 11] == 0.001)
mean(lrf.betas[, 12] == 0.001)

mean(lra.betas[, 10] == 0.001)
mean(lra.betas[, 11] == 0.001)
mean(lra.betas[, 12] == 0.001)

mean(dfa.betas[, 6] == 0.001)
mean(dfa.betas[, 7] == 0.001)
mean(dfa.betas[, 8] == 0.001)

# PE and ME with replicates
lrf.betas <- table3r.betas[[3]][[1]]
lra.betas <- table3r.betas[[3]][[2]]
dfa.betas <- table3r.betas[[3]][[3]]

plot(lrf.betas[, 2], lra.betas[, 2])
cor(lrf.betas[, 2], lra.betas[, 2])
max(abs(lrf.betas[, 2] - lra.betas[, 2]))

x <- dfa.betas[, 9]
y <- dfa.betas[, 11] / dfa.betas[, 9]
fit <- lm(y ~ x)
summary(fit)

plot(x, y,
     main = "Table 3 - PE and ME w/ replicates",
     ylab = "Bias-adjusted log-OR / MLE",
     xlab = "MLE")
abline(fit, col = "blue")

lrf.ses <- table3r.ses[[3]][[1]]
lra.ses <- table3r.ses[[3]][[2]]
dfa.ses <- table3r.ses[[3]][[3]]

table(lrn.ses[, 11])
table(lrf.ses[, 13])
table(lra.ses[, 13])
table(dfa.ses[, 3])

estimates <- cbind(lrf.betas[, 2], lra.betas[, 2], dfa.betas[, 11])
ses = cbind(lrf.ses[, 2], lra.ses[, 2], dfa.ses[, 2])
sumsim(estimates = estimates,
       ses = ses,
       truth = 0.2)

sprintf("%.3f", mean(lrf.betas[, 2]) - 0.2)
sprintf("%.3f", mean(lra.betas[, 2]) - 0.2)
sprintf("%.3f", mean(dfa.betas[, 9] - 0.2))
sprintf("%.3f", mean(dfa.betas[, 11] - 0.2))

sprintf("%.3f", sd(lrf.betas[, 2]))
sprintf("%.3f", sd(lra.betas[, 2]))
sprintf("%.3f", sd(dfa.betas[, 9]))
sprintf("%.3f", sd(dfa.betas[, 11]))

sprintf("%.3f", mean(lrf.ses[, 2]))
sprintf("%.3f", mean(lra.ses[, 2]))
sprintf("%.3f", mean(dfa.ses[, 1]))
sprintf("%.3f", mean(dfa.ses[, 2]))

sprintf("%.4f", mean((lrf.betas[, 2] - 0.2)^2))
sprintf("%.4f", mean((lra.betas[, 2] - 0.2)^2))
sprintf("%.4f", mean((dfa.betas[, 9] - 0.2)^2))
sprintf("%.4f", mean((dfa.betas[, 11] - 0.2)^2))

zval <- abs(qnorm(0.025))
sprintf("%.3f", mean(lrf.betas[, 2] - zval * lrf.ses[, 2] < 0.2 & lrf.betas[, 2] + zval * lrf.ses[, 2] > 0.2))
sprintf("%.3f", mean(lra.betas[, 2] - zval * lra.ses[, 2] < 0.2 & lra.betas[, 2] + zval * lra.ses[, 2] > 0.2))
sprintf("%.3f", mean(dfa.betas[, 9] - zval * dfa.ses[, 1] < 0.2 & dfa.betas[, 9] + zval * dfa.ses[, 1] > 0.2))
sprintf("%.3f", mean(dfa.betas[, 11] - zval * dfa.ses[, 2] < 0.2 & dfa.betas[, 11] + zval * dfa.ses[, 2] > 0.2))

sum(sign(dfa.betas[, 9]) != sign(dfa.betas[, 11]))

sum(lrf.betas[, 10] == 0.001)
sum(lrf.betas[, 11] == 0.001)
sum(lrf.betas[, 12] == 0.001)

sum(lra.betas[, 10] == 0.001)
sum(lra.betas[, 11] == 0.001)
sum(lra.betas[, 12] == 0.001)

sum(dfa.betas[, 6] == 0.001)
sum(dfa.betas[, 7] == 0.001)
sum(dfa.betas[, 8] == 0.001)

# Even after 5x increase in sample size, PE/ME without replicates unstable.
load("table3_n5x_betas.rda")
lrf.betas <- table3.n5x.betas[[1]]
lra.betas <- table3.n5x.betas[[2]]
dfa.betas <- table3.n5x.betas[[3]]

mean(! inside(lrf.betas[, 2], c(-1, 1)))
mean(! inside(lra.betas[, 2], c(-1, 1)))
mean(! inside(dfa.betas[, 9], c(-1, 1)))

# Skewness with and without replicates??
# skewness(table3c.lr.approx[, 2])
# skewness(table3c.disc[, 11])

# Figure 1 ----------------------------------------------------------------

fig1.lrf1 <- table3.betas[[3]][[3]]
fig1.lrf2 <- table3r.betas[[3]][[1]]

fig1.dfa1 <- table3.betas[[3]][[7]]
fig1.dfa2 <- table3r.betas[[3]][[3]]

range(fig1.lrf1[, 2])
range(fig1.dfa1[, 9])

png("fig1.png", width = 7, height = 7, units = "in", res = 900)

# par(mfrow = c(2, 2))
# par(mar = c(5.1, 4.1, 4.1, 2.1))
# #par(mar = c(6.1, 5.1, 3.1, 2.1))
# par(oma = c(0, 0, 0, 0))
# #par(oma = c(0, 0, 3, 0))

par(mfrow = c(2, 2))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(6.1, 5.1, 3.1, 2.1))
par(oma = c(0, 0, 3, 0))

hist(trim(fig1.lrf1[, 2], cutpoints = c(-1, 2)),
     main = "LRF",
     xlab = expression(paste("log-", hat(OR), sep = "")),
     xlim = c(-0.5, 2.0), breaks = 50)
hist(trim(fig1.dfa1[, 9], cutpoints = c(-1, 2)),
     main = "DFA",
     xlab = expression(paste("log-", hat(OR), sep = "")),
     xlim = c(-0.5, 2.0), breaks = 50)
mtext(text = "Without Replicates", side = 3, line = 3, adj = -2.6, cex = 1.25)

hist(fig1.lrf2[, 2],
     main = "LRF",
     xlab = expression(paste("log-", hat(OR), sep = "")), xlim = c(-0.5, 2.0))
hist(fig1.dfa2[, 11],
     main = "DFA",
     xlab = expression(paste("log-", hat(OR), sep = "")), xlim = c(-0.5, 2.0))
mtext(text = "With Replicates", side = 3, line = 3, adj = -1.6, cex = 1.25)

dev.off()

# PE and ME, large n
load("table3_largen_results.rda")
table3.largen.results[[1]]$theta.hat
table3.largen.results[[2]]$estimates

# Skewness w/o replicates with 5x the sample size
load("table3_noreps_list.rda")
length(table3.noreps.list)
headtail(sort(table3.noreps.list[[1]][, 2]), n = 50)
headtail(sort(table3.noreps.list[[2]][, 11]), n = 50)

par(mfrow = c(2, 1))
hist(table3.noreps.list[[1]][, 2], breaks = 100)
hist(table3.noreps.list[[2]][, 11], breaks = 100)

mean(table3.noreps.list[[1]][, 2] > 1)
mean(table3.noreps.list[[2]][, 11] > 1)
mean(table3.noreps.list[[2]][, 9] > 1)

hist(trim(table3.noreps.list[[1]][, 2], cutpoints = c(-1, 1)), breaks = 50)
hist(trim(table3.noreps.list[[2]][, 11], cutpoints = c(-1, 1)), breaks = 50)
hist(trim(table3.noreps.list[[2]][, 9], cutpoints = c(-1, 1)), breaks = 50)

median(table3.noreps.list[[1]][, 2])
median(table3.noreps.list[[2]][, 11])
median(table3.noreps.list[[2]][, 9])

diff(quantile(table3.list[[3]][[7]][, 2], probs = c(0.1, 0.9)))
diff(quantile(table3.noreps.list[[1]][, 2], probs = c(0.1, 0.9)))

diff(quantile(table3.list[[3]][[11]][, 11], probs = c(0.1, 0.9)))
diff(quantile(table3.noreps.list[[2]][, 11], probs = c(0.1, 0.9)))



# Figure 2 ----------------------------------------------------------------

# Verify full ML and approx. ML are almost identical
load("fig2mla_betas.rda")
load("fig2mlb_betas.rda")
load("fig2mlc_betas.rda")

# Values are abs(max diff), Pearson r for P-1-2-3; abs (max diff. Pearson r) for P-1-5

# PE only:
# 1: n/a
# 2: 0.0013, 0.99998; 0.0024, 0.99987
# 3: 0.0025, 0.99994; 0.0078, 0.99962
# 4: 0.0011, 0.99992; 0.0057, 0.99920
# 5: 0.0028, 0.99994; 0.0064, 0.99946
# 6: 0.0105, 0.99973; 0.0054, 0.99915

ii <- 6
lrf <- fig2mla.betas[[ii]][, 3]
lra <- fig2mla.betas[[ii]][, 4]
plot(lra, lrf)
points(c(-1, 1), c(-1, 1), type = "l")
max(abs(lrf - lra))
cor(lrf, lra)

lrf <- fig2mla.betas[[ii]][, 6]
lra <- fig2mla.betas[[ii]][, 7]
plot(lra, lrf)
max(abs(lrf - lra))
cor(lrf, lra)

# ME only w/ replicates:
# 1: n/a
# 2: 0.0007, 0.99999; 0.0018, 0.99991
# 3: 0.0012, 0.99999; 0.0048, 0.99968
# 4: 0.0036, 0.99995; 0.0056, 0.99942
# 5: 0.0065, 0.99992; 0.0126, 0.99955
# 6: 0.0376, 0.99983; 0.0226, 0.99901

ii <- 6
lrf <- fig2mlb.betas[[ii]][, 7]
lra <- fig2mlb.betas[[ii]][, 8]
plot(lra, lrf)
points(c(-1, 1), c(-1, 1), type = "l")
max(abs(lrf - lra))
cor(lrf, lra)

lrf <- fig2mlb.betas[[ii]][, 13]
lra <- fig2mlb.betas[[ii]][, 14]
plot(lra, lrf)
points(c(-1, 1), c(-1, 1), type = "l")
max(abs(lrf - lra))
cor(lrf, lra)

# PE and ME w/ replicates:
# 1: 0.0020, 0.99996; 0.0032, 0.99976
# 2: 0.0014, 0.99995; 0.0056, 0.99939
# 3: 0.0028, 0.99990; 0.0121, 0.99951
# 4: 0.0063, 0.99983; 0.0070, 0.99936
# 5: 0.0090, 0.99980; 0.0103, 0.99923
# 6: 0.0117, 0.99979; 0.0082, 0.99878

ii <- 6 # have to fill in
lrf <- fig2mlc.betas[[ii]][, 4] # for ii = 1 only
lrf <- fig2mlc.betas[[ii]][, 7]
lra <- fig2mlc.betas[[ii]][, 8]
plot(lra, lrf)
points(c(-1, 1), c(-1, 1), type = "l")
max(abs(lrf - lra))
cor(lrf, lra)

lrf <- fig2mlc.betas[[ii]][, 10]
lra <- fig2mlc.betas[[ii]][, 11]
plot(lra, lrf)
points(c(-1, 1), c(-1, 1), type = "l")
max(abs(lrf - lra))
cor(lrf, lra)


head(fig2mla.betas[[2]])

length(fig2mlb.betas)
head(fig2mlb.betas[[1]])
plot(fig2mlb.betas[[1]][, 4], fig2mlb.betas[[2]][, 5])

# PE only

# Load simulation results
load("fig2a_betas.rda")
load("fig2a_blowups.rda")
load("fig2b_betas.rda")
load("fig2b_blowups.rda")
load("fig2c_betas.rda")
load("fig2c_blowups.rda")

# Look at blowups
sapply(fig2a.blowups, function(x) apply(x, 2, sum))
sapply(fig2b.blowups, function(x) apply(x, 2, sum))
sapply(fig2c.blowups, function(x) apply(x, 2, sum))

# Get means and variances
(fig2a.means <- sapply(fig2a.betas, function(x) apply(x, 2, mean)))
(fig2b.means <- sapply(fig2b.betas, function(x) apply(x, 2, mean)))
(fig2c.means <- sapply(fig2c.betas, function(x) apply(x, 2, mean)))

(fig2a.medians <- sapply(fig2a.betas, function(x) apply(x, 2, median)))
(fig2b.medians <- sapply(fig2b.betas, function(x) apply(x, 2, median)))
(fig2c.medians <- sapply(fig2c.betas, function(x) apply(x, 2, median)))

(fig2a.vars <- sapply(fig2a.betas, function(x) apply(x, 2, var)))
(fig2b.vars <- sapply(fig2b.betas, function(x) apply(x, 2, var)))
(fig2c.vars <- sapply(fig2c.betas, function(x) apply(x, 2, var)))

(fig2a.tvars <- sapply(fig2a.betas, function(x) apply(x, 2, function(x) var(trim(x, p = c(0.05, 0.95))))))
(fig2b.tvars <- sapply(fig2b.betas, function(x) apply(x, 2, function(x) var(trim(x, p = c(0.05, 0.95))))))
(fig2c.tvars <- sapply(fig2c.betas, function(x) apply(x, 2, function(x) var(trim(x, p = c(0.05, 0.95))))))

(fig2a.iqrs <- sapply(fig2a.betas, function(x) apply(x, 2, function(x) IQR(x, na.rm = TRUE))))
(fig2b.iqrs <- sapply(fig2b.betas, function(x) apply(x, 2, function(x) IQR(x, na.rm = TRUE))))
(fig2c.iqrs <- sapply(fig2c.betas, function(x) apply(x, 2, function(x) IQR(x, na.rm = TRUE))))

(fig2a.1090 <- sapply(fig2a.betas, function(x) apply(x, 2, function(x) diff(quantile(x, probs = c(0.1, 0.9), na.rm = TRUE)))))
(fig2b.1090 <- sapply(fig2b.betas, function(x) apply(x, 2, function(x) diff(quantile(x, probs = c(0.1, 0.9))))))
(fig2c.1090 <- sapply(fig2c.betas, function(x) apply(x, 2, function(x) diff(quantile(x, probs = c(0.1, 0.9))))))

# Look for outliers
hist(fig2a.betas[[6]][, 1])
hist(fig2a.betas[[6]][, 4])
hist(fig2a.betas[[6]][, 7]) # Bug here, have to re-run

hist(fig2a.betas[[6]][, 2])
hist(fig2a.betas[[6]][, 5])
hist(fig2a.betas[[6]][, 8])

which(! inside(fig2b.betas[[6]][, 1], c(-1, 1)))
sum(! inside(fig2b.betas[[6]][, 1], c(-1, 1)))
locs <- which(fig2b.betas[[6]][, 1] < 1)
hist(fig2b.betas[[6]][, 1], breaks = 30) # Some outliers!
hist(fig2b.betas[[6]][locs, 1], breaks = 30) # Some outliers!
hist(fig2b.betas[[6]][, 5], breaks = 30) # Not bad
hist(fig2b.betas[[6]][, 9], breaks = 30) # Not bad

which(! inside(fig2b.betas[[6]][, 2], c(-1, 1)))
sum(! inside(fig2b.betas[[6]][, 2], c(-1, 1)))
hist(fig2b.betas[[6]][, 2], breaks = 30)
hist(fig2b.betas[[6]][locs, 2], breaks = 30)
hist(fig2b.betas[[6]][, 6]) # 1 outlier
hist(fig2b.betas[[6]][, 10]) # 1 outlier
which.min(fig2b.betas[[6]][, 10])

(fig2c.extreme <- sapply(fig2c.betas, function(x) apply(x, 2, function(x) sum(x < -1 | x > 1))))

# Create plot with sample variances
sigsq.vals <- c(0, 0.1, 0.25, 0.5, 1, 2)
png("fig2_vars.png", width = 5.5, height = 8.5, units = "in", res = 900)

par(mfrow = c(3, 2))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(6.1, 5.1, 3.1, 2.1))
par(oma = c(0, 0, 0, 0))
par(oma = c(0, 0, 3, 0))

# PE only
plot(1: length(sigsq.vals) - 0.15, fig2a.vars[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.01),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.vars[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.vars[4, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.vars[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2a.vars[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.01),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.vars[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.vars[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.vars[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error Only", side = 3, line = 3, adj = -450, cex = 1.1)

# ME only
plot(1: length(sigsq.vals) - 0.15, fig2b.vars[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.05),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.vars[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.vars[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.vars[9, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2b.vars[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.015),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.vars[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.vars[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.vars[10, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Measurement Error Only", side = 3, line = 3, adj = 7.25, cex = 1.1)

# PE and ME
plot(1: length(sigsq.vals) - 0.15, fig2c.vars[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.05),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.vars[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.vars[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.vars[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2c.vars[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("90th - 10th perc. for ", hat(beta)[x], sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.05),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.vars[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.vars[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.vars[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error and Measurement Error", side = 3, line = 3, adj = 1.3, cex = 1.1)

dev.off()



# Create plot with 10th to 90th percentile
sigsq.vals <- c(0, 0.1, 0.25, 0.5, 1, 2)
png("fig2_p10p90.png", width = 5.5, height = 8.5, units = "in", res = 900)

par(mfrow = c(3, 2))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(6.1, 5.1, 3.1, 2.1))
par(oma = c(0, 0, 0, 0))
par(oma = c(0, 0, 3, 0))

# PE only
plot(1: length(sigsq.vals) - 0.15, fig2a.1090[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.1090[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.1090[4, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.1090[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2a.1090[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.1090[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.1090[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.1090[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error Only", side = 3, line = 3, adj = -450, cex = 1.1)


# ME only
plot(1: length(sigsq.vals) - 0.15, fig2b.1090[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.1090[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.1090[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.1090[9, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2b.1090[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.1090[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.1090[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.1090[10, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Measurement Error Only", side = 3, line = 3, adj = 7.25, cex = 1.1)

# PE and ME
plot(1: length(sigsq.vals) - 0.15, fig2c.1090[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.1090[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.1090[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.1090[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2c.1090[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("90th - 10th percentile for log-", hat(OR), sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.3),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.1090[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.1090[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.1090[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error and Measurement Error", side = 3, line = 3, adj = 1.3, cex = 1.1)

dev.off()


# Create plot with IQRs
sigsq.vals <- c(0, 0.1, 0.25, 0.5, 1, 2)
png("fig2_iqr.png", width = 5.5, height = 8.5, units = "in", res = 900)

par(mfrow = c(3, 2))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(6.1, 5.1, 3.1, 2.1))
par(oma = c(0, 0, 0, 0))
par(oma = c(0, 0, 3, 0))

# PE only
plot(1: length(sigsq.vals) - 0.15, fig2a.iqrs[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.iqrs[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.iqrs[4, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.iqrs[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2a.iqrs[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2a.iqrs[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2a.iqrs[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2a.iqrs[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error Only", side = 3, line = 3, adj = -450, cex = 1.1)

# ME only
plot(1: length(sigsq.vals) - 0.15, fig2b.iqrs[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.iqrs[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.iqrs[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.iqrs[9, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2b.iqrs[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2b.iqrs[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2b.iqrs[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2b.iqrs[10, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Measurement Error Only", side = 3, line = 3, adj = 7.25, cex = 1.1)

# PE and ME
plot(1: length(sigsq.vals) - 0.15, fig2c.iqrs[1, ], type = "n",
     main = "Logistic Regression",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.iqrs[1, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.iqrs[5, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.iqrs[7, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

plot(1: length(sigsq.vals) - 0.15, fig2c.iqrs[2, ], type = "n",
     main = "Discriminant Function",
     ylab = expression(paste("IQR for ", hat(beta)[x], sep = "")),
     xlab = expression(paste(sigma[m]^2, " (", sigma[p]^2, " = 0.25)", sep = "")),
     ylim = c(0, 0.15),
     xlim = c(0.5, length(sigsq.vals) + 0.5),
     xaxt = "n")
grid(nx = NA, ny = NULL)
points(1: length(sigsq.vals) - 0.15, fig2c.iqrs[2, ], type = "p", pch = 16, cex = 0.65)
points(1: length(sigsq.vals), fig2c.iqrs[6, ], type = "p", pch = 17, cex = 0.75)
points(1: length(sigsq.vals) + 0.15, fig2c.iqrs[8, ], type = "p", pch = 15, cex = 0.65)
axis(side = 1, at = 1: length(sigsq.vals), labels = sigsq.vals, cex.axis = 0.8)
legend("topleft", pch = c(16, 17, 15), cex = 0.8, pt.cex = c(0.65, 0.75, 0.65),
       legend = c("Traditional", "P-1-2-3", "P-1-5"))

mtext(text = "Processing Error and Measurement Error", side = 3, line = 3, adj = 1.3, cex = 1.1)

dev.off()














plot(sigsq.vals, fig1b.1090[2, ], type = "p", col = "black",
     main = "ME only, Disc. Function Estimates",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.3),
     xaxt = "n",
     pch = 4, cex = 0.7)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)
points(sigsq.vals, fig1b.1090[4, ], type = "p", pch = 1, cex = 0.9)
points(sigsq.vals, fig1b.1090[6, ], type = "p", pch = 16, cex = 0.9)






plot(sigsq.vals, fig1b.iqrs[1, ], type = "p", col = "black",
     main = "ME only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.25),
     xaxt = "n",
     pch = 4, cex = 0.7)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)
points(sigsq.vals, fig1b.iqrs[5, ], type = "p", pch = 1, cex = 0.9)
points(sigsq.vals, fig1b.iqrs[15, ], type = "p", pch = 16, cex = 0.9)

plot(sigsq.vals, fig1c.iqrs[1, ], type = "p", col = "black",
     main = "PE and ME",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.5),
     xaxt = "n",
     pch = 4, cex = 0.7)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)
points(sigsq.vals, fig1c.iqrs[3, ], type = "p", pch = 1, cex = 0.9)
points(sigsq.vals, fig1c.iqrs[9, ], type = "p", pch = 16, cex = 0.9)




plot(sigsq.vals, fig1a.vars[1, ], type = "p", col = "black",
     main = "PE only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.015),
     xaxt = "n",
     pch = 1, cex = 0.9)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)
points(sigsq.vals, fig1a.vars[3, ], type = "p", pch = 10, cex = 0.9)
points(sigsq.vals, fig1a.vars[9, ], type = "p", pch = 19, cex = 0.9)


points(sigsq.vals, fig1a.vars[3, ], type = "p", pch = 4, cex = 0.8)
axis(side = 1, at = sigsq_p.vals, cex.axis = 0.6)






sort(fig1a.betas[[1]], decreasing = TRUE)[1: 20]

hist(fig1b.betas[[1]])
hist(fig1b.betas[[2]])
hist(fig1b.betas[[3]])
hist(fig1b.betas[[4]])

hist(fig1b.betas[[5]]) # Problem
sort(fig1b.betas[[5]]) # 1 value of 23959

hist(fig1b.betas[[6]]) # Problem
sort(fig1b.betas[[6]]) # 3 values over 6.51

hist(fig1b.betas[[7]]) # Not bad

hist(fig1b.betas[[8]]) # Problem
sort(fig1b.betas[[8]]) # 1 value of 6455

hist(fig1b.betas[[9]]) # Problem
sort(fig1b.betas[[9]]) # Some very high, but only real crazy is 720

hist(fig1b.betas[[10]]) # Problem
sort(fig1b.betas[[10]]) # Start getting crazy at 178

(fig1b.tmeans <- sapply(fig1b.betas, function(x) apply(x, 2, function(x) mean(x, trim = 0.02))))
(fig1b.tmeans <- sapply(fig1b.betas, function(x) apply(x, 2, function(x) mean(x, trim = 0.02))))

# Create plot using IQRs
sigsq.vals <- c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5)
#png("fig1.png", width = 5, height = 7, units = "in", res = 500)
par(mfrow = c(3, 1))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(5.1, 5.1, 4.1, 2.1))

plot(sigsq.vals, fig1a.iqrs[1, ], type = "p", col = "black",
     main = "PE only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.2),
     xaxt = "n",
     pch = 4, cex = 0.8)
points(sigsq.vals, fig1a.iqrs[2, ], type = "p", pch = 1, cex = 0.8)
points(sigsq.vals, fig1a.iqrs[3, ], type = "p", pch = 2, cex = 0.8)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)

plot(sigsq.vals, fig1b.iqrs[1, ], type = "p", col = "black",
     main = "ME only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.3),
     xaxt = "n",
     pch = 4, cex = 0.8)
points(sigsq.vals, fig1b.iqrs[2, ], type = "p", pch = 1, cex = 0.8)
points(sigsq.vals, fig1b.iqrs[3, ], type = "p", pch = 16, cex = 0.8)
points(sigsq.vals, fig1b.iqrs[4, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1b.iqrs[5, ], type = "p", pch = 17, cex = 0.8)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)

plot(sigsq.vals, fig1c.iqrs[1, ], type = "p", col = "black",
     main = "PE and ME",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.3),
     xaxt = "n",
     pch = 4, cex = 0.8)
points(sigsq.vals, fig1c.iqrs[2, ], type = "p", pch = 1, cex = 0.8)
points(sigsq.vals, fig1c.iqrs[3, ], type = "p", pch = 2, cex = 0.8)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)


# Try new version of plot... Would like to show both lr and disc...

# Create plot using variances
sigsq.vals <- c(0, 0.1, 0.25, 0.5, 1, 2)
#png("fig1.png", width = 5, height = 7, units = "in", res = 500)
par(mfrow = c(3, 2))
#par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mar = c(5.1, 5.1, 4.1, 2.1))

plot(sigsq.vals, fig1a.vars[1, ], type = "p", col = "black",
     main = "PE only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[p]^2),
     ylim = c(0, 0.015),
     xaxt = "n",
     pch = 1, cex = 0.8)


points(sigsq.vals, fig1a.vars[2, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1a.vars[3, ], type = "p", pch = 4, cex = 0.8)
axis(side = 1, at = sigsq_p.vals, cex.axis = 0.6)

plot(sigsq.vals, fig1b.vars[1, ], type = "p", col = "black",
     main = "ME only",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.05),
     xaxt = "n",
     pch = 1, cex = 0.8)
points(sigsq.vals, fig1b.vars[2, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1b.vars[3, ], type = "p", pch = 4, cex = 0.8)
points(sigsq.vals, fig1b.vars[4, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1b.vars[5, ], type = "p", pch = 4, cex = 0.8)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)

# plot(sigsq.vals, fig1b.iqrs[1, ], type = "p", col = "black",
#      main = "ME only",
#      ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
#      xlab = expression(sigma[m]^2),
#      ylim = c(0, 0.3),
#      xaxt = "n",
#      pch = 1, cex = 0.8)
# points(sigsq.vals, fig1b.iqrs[2, ], type = "p", pch = 2, cex = 0.8)
# points(sigsq.vals, fig1b.iqrs[3, ], type = "p", pch = 4, cex = 0.8)
# points(sigsq.vals, fig1b.iqrs[4, ], type = "p", pch = 2, cex = 0.8)
# points(sigsq.vals, fig1b.iqrs[5, ], type = "p", pch = 4, cex = 0.8)
# axis(side = 1, at = sigsq.vals, cex.axis = 0.6)

plot(sigsq.vals, fig1c.vars[1, ], type = "p", col = "black",
     main = "PE and ME",
     ylab = expression(paste("Sample variance of ", hat(beta)[x], sep = "")),
     xlab = expression(sigma[m]^2),
     ylim = c(0, 0.02),
     xaxt = "n",
     pch = 1, cex = 0.8)
points(sigsq.vals, fig1c.vars[2, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1c.vars[3, ], type = "p", pch = 4, cex = 0.8)
points(sigsq.vals, fig1c.vars[4, ], type = "p", pch = 2, cex = 0.8)
points(sigsq.vals, fig1b.vars[5, ], type = "p", pch = 4, cex = 0.8)
axis(side = 1, at = sigsq.vals, cex.axis = 0.6)



# Get SD's
(f1b.means <- sapply(f1b.list, function(x) apply(x, 2, mean)))
(f1b.sds <- sapply(f1b.list, function(x) apply(x, 2, sd)))

plot(sigsq_m.vals, f1b.sds[1, ]^2, col = "black", ylim = c(0, 0.3))
points(sigsq_m.vals, f1b.sds[2, ], col = "red")
points(sigsq_m.vals, f1b.sds[3, ], col = "blue")
points(sigsq_m.vals, f1b.sds[4, ], col = "purple")
points(sigsq_m.vals, f1b.sds[5, ], col = "orange")








# Parameters
sigsq_p.vals <- c(sigsq_p, 0, sigsq_p)
sigsq_m.vals <- c(0, sigsq_m, sigsq_m)
(theta <- c(betas, alphas, sigsq_x, sigsq_p, sigsq_m))
n <- 686
trials <- 1000

# One trial with large n: PE only
n <- 1000000
sigsq_p.ii <- sigsq_p
sigsq_m.ii <- 0

set.seed(123)
c1 <- sample(size = n, x = age.vals, prob = age.probs, replace = TRUE)
c2 <- rbinom(n = n, size = 1, prob = p_nw)
c3 <- rbinom(n = n, size = 1, prob = p_smoke)
x <- rnorm(n = n, mean = alphas[1] + alphas[2] * c1 + alphas[3] * c2 +
             alphas[4] * c3, sd = sqrt(sigsq_x))
p_y.x <- (1 + exp(-betas[1] - betas[2] * x - betas[3] * c1 - betas[4] * c2 -
                    betas[5] * c3))^(-1)
y <- rbinom(n = n, size = 1, prob = p_y.x)
dat.ind <- data.frame(y = y, x = x, c1 = c1, c2 = c2, c3 = c3)

locs.y1 <- which(y == 1)
locs.y0 <- which(y == 0)
n.y1 <- length(locs.y1)
n.y0 <- length(locs.y0)
dat.ind.y1 <- dat.ind[locs.y1, ]
dat.ind.y0 <- dat.ind[locs.y0, ]

n.y1pools.23 <- ceiling(n.y1 / 6)
n.y1pools.1 <- n.y1 - n.y1pools.23 * 5
dat.y1.p <- p.neighbors(dat = dat.ind.y1, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y1pools.23, 2), n.y1pools.1))
dat.y1.p$y_onezero <- 1

n.y0pools.23 <- ceiling(n.y0 / 6)
n.y0pools.1 <- n.y0 - n.y0pools.23 * 5
dat.y0.p <- p.neighbors(dat = dat.ind.y0, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y0pools.23, 2), n.y0pools.1))
dat.y0.p$y_onezero <- 0

dat.p <- rbind(dat.y1.p, dat.y0.p)

n.pools <- nrow(dat.p)
dat.p$xtilde <-
  (dat.p$x / dat.p$g + rnorm(n = n.pools, sd = sqrt(sigsq_p.ii)) *
     ifelse(dat.p$g > 1, 1, 0) +
     rnorm(n = n.pools, sd = sqrt(sigsq_m.ii))) *
  dat.p$g

# lr.full <- p.logistic.xerrors(g = dat.p$g,
#                               y = dat.p$y_onezero,
#                               xtilde = dat.p$xtilde,
#                               c = dat.p[, c("c1", "c2", "c3")],
#                               error.type = "processing",
#                               approx.integral = FALSE,
#                               integrate.tol = 1e-7,
#                               estimate.var = FALSE,
#                               lower = c(rep(-Inf, 9), rep(1e-3, 2)),
#                               control = list(trace = 1, rel.tol = 1e-9))
# sprintf("%.3f", lr.full$theta.hat[c(1: 5, 10: 11)])

lr.approx <- p.logistic.xerrors(g = dat.p$g,
                                y = dat.p$y_onezero,
                                xtilde = dat.p$xtilde,
                                c = dat.p[, c("c1", "c2", "c3")],
                                error.type = "processing",
                                approx.integral = TRUE,
                                estimate.var = FALSE,
                                lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", lr.approx$theta.hat[c(1: 5, 10: 11)])
v1 <- lr.approx$theta.hat[c(1:5, 10: 11)]
v2 <- theta[c(1: 5, 10: 11)]
(v1 - v2) / ((v1 + v2)/2) * 100

disc <- p.disc.xerrors(g = dat.p$g,
                       y = dat.p$y,
                       xtilde = dat.p$xtilde,
                       c = dat.p[, c("c1", "c2", "c3")],
                       error.type = "processing",
                       lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                       control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", disc$estimates[c("logOR_adj.hat", "sigsq_p")])


# One trial with large n: ME only
sigsq_p.ii <- 0
sigsq_m.ii <- sigsq_m

c1 <- sample(size = n, x = age.vals, prob = age.probs, replace = TRUE)
c2 <- rbinom(n = n, size = 1, prob = p_nw)
c3 <- rbinom(n = n, size = 1, prob = p_smoke)
x <- rnorm(n = n, mean = alphas[1] + alphas[2] * c1 + alphas[3] * c2 +
             alphas[4] * c3, sd = sqrt(sigsq_x))
p_y.x <- (1 + exp(-betas[1] - betas[2] * x - betas[3] * c1 - betas[4] * c2 -
                    betas[5] * c3))^(-1)
y <- rbinom(n = n, size = 1, prob = p_y.x)
dat.ind <- data.frame(y = y, x = x, c1 = c1, c2 = c2, c3 = c3)

locs.y1 <- which(y == 1)
locs.y0 <- which(y == 0)
n.y1 <- length(locs.y1)
n.y0 <- length(locs.y0)
dat.ind.y1 <- dat.ind[locs.y1, ]
dat.ind.y0 <- dat.ind[locs.y0, ]

n.y1pools.23 <- ceiling(n.y1 / 6)
n.y1pools.1 <- n.y1 - n.y1pools.23 * 5
dat.y1.p <- p.neighbors(dat = dat.ind.y1, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y1pools.23, 2), n.y1pools.1))
dat.y1.p$y_onezero <- 1

n.y0pools.23 <- ceiling(n.y0 / 6)
n.y0pools.1 <- n.y0 - n.y0pools.23 * 5
dat.y0.p <- p.neighbors(dat = dat.ind.y0, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y0pools.23, 2), n.y0pools.1))
dat.y0.p$y_onezero <- 0

dat.p <- rbind(dat.y1.p, dat.y0.p)

n.pools <- nrow(dat.p)
dat.p$xtilde <-
  (dat.p$x / dat.p$g + rnorm(n = n.pools, sd = sqrt(sigsq_p.ii)) *
     ifelse(dat.p$g > 1, 1, 0) +
     rnorm(n = n.pools, sd = sqrt(sigsq_m.ii))) *
  dat.p$g

# lr.full <- p.logistic.xerrors(g = dat.p$g,
#                               y = dat.p$y_onezero,
#                               xtilde = dat.p$xtilde,
#                               c = dat.p[, c("c1", "c2", "c3")],
#                               error.type = "measurement",
#                               approx.integral = FALSE,
#                               integrate.tol = 1e-7,
#                               estimate.var = FALSE,
#                               lower = c(rep(-Inf, 9), rep(1e-3, 2)),
#                               control = list(trace = 1, rel.tol = 1e-9))
# sprintf("%.3f", lr.full$theta.hat[c(1: 5, 10: 11)])

lr.approx <- p.logistic.xerrors(g = dat.p$g,
                                y = dat.p$y_onezero,
                                xtilde = dat.p$xtilde,
                                c = dat.p[, c("c1", "c2", "c3")],
                                error.type = "measurement",
                                approx.integral = TRUE,
                                estimate.var = FALSE,
                                lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", lr.approx$theta.hat[c(1: 5, 10: 11)])
v1 <- lr.approx$theta.hat[c(1: 5, 10: 11)]
v2 <- theta[c(1: 5, 10, 12)]
(v1 - v2) / ((v1 + v2) / 2) * 100

disc <- p.disc.xerrors(g = dat.p$g,
                       y = dat.p$y,
                       xtilde = dat.p$xtilde,
                       c = dat.p[, c("c1", "c2", "c3")],
                       error.type = "measurement",
                       lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                       control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", disc$estimates[c("logOR_adj.hat", "sigsq_m")])

lr.naive <- p.logistic.xerrors(g = dat.p$g,
                               y = dat.p$y_onezero,
                               xtilde = dat.p$xtilde,
                               c = dat.p[, c("c1", "c2", "c3")],
                               error.type = "neither",
                               approx.integral = TRUE,
                               estimate.var = FALSE,
                               lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                               control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", lr.naive$theta.hat[c(1: 5, 10)])


# One trial with large n: PE and ME
sigsq_p.ii <- sigsq_p
sigsq_m.ii <- sigsq_m

c1 <- sample(size = n, x = age.vals, prob = age.probs, replace = TRUE)
c2 <- rbinom(n = n, size = 1, prob = p_nw)
c3 <- rbinom(n = n, size = 1, prob = p_smoke)
x <- rnorm(n = n, mean = alphas[1] + alphas[2] * c1 + alphas[3] * c2 +
             alphas[4] * c3, sd = sqrt(sigsq_x))
p_y.x <- (1 + exp(-betas[1] - betas[2] * x - betas[3] * c1 - betas[4] * c2 -
                    betas[5] * c3))^(-1)
y <- rbinom(n = n, size = 1, prob = p_y.x)
dat.ind <- data.frame(y = y, x = x, c1 = c1, c2 = c2, c3 = c3)

locs.y1 <- which(y == 1)
locs.y0 <- which(y == 0)
n.y1 <- length(locs.y1)
n.y0 <- length(locs.y0)
dat.ind.y1 <- dat.ind[locs.y1, ]
dat.ind.y0 <- dat.ind[locs.y0, ]

n.y1pools.23 <- ceiling(n.y1 / 6)
n.y1pools.1 <- n.y1 - n.y1pools.23 * 5
dat.y1.p <- p.neighbors(dat = dat.ind.y1, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y1pools.23, 2), n.y1pools.1))
dat.y1.p$y_onezero <- 1

n.y0pools.23 <- ceiling(n.y0 / 6)
n.y0pools.1 <- n.y0 - n.y0pools.23 * 5
dat.y0.p <- p.neighbors(dat = dat.ind.y0, pool.sizes = c(3, 2, 1),
                        n.pools = c(rep(n.y0pools.23, 2), n.y0pools.1))
dat.y0.p$y_onezero <- 0

dat.p <- rbind(dat.y1.p, dat.y0.p)

n.pools <- nrow(dat.p)
dat.p$xtilde <-
  (dat.p$x / dat.p$g + rnorm(n = n.pools, sd = sqrt(sigsq_p.ii)) *
     ifelse(dat.p$g > 1, 1, 0) +
     rnorm(n = n.pools, sd = sqrt(sigsq_m.ii))) *
  dat.p$g

lr.full <- p.logistic.xerrors(g = dat.p$g,
                              y = dat.p$y_onezero,
                              xtilde = dat.p$xtilde,
                              c = dat.p[, c("c1", "c2", "c3")],
                              error.type = "both",
                              approx.integral = FALSE,
                              integrate.tol = 1e-7,
                              estimate.var = FALSE,
                              lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                              control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", lr.full$theta.hat[c(1: 5, 10: 12)])

lr.approx <- p.logistic.xerrors(g = dat.p$g,
                                y = dat.p$y_onezero,
                                xtilde = dat.p$xtilde,
                                c = dat.p[, c("c1", "c2", "c3")],
                                error.type = "both",
                                approx.integral = TRUE,
                                estimate.var = FALSE,
                                lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", lr.approx$theta.hat[c(1: 5, 10: 12)])

disc <- p.disc.xerrors(g = dat.p$g,
                       y = dat.p$y,
                       xtilde = dat.p$xtilde,
                       c = dat.p[, c("c1", "c2", "c3")],
                       error.type = "both",
                       lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                       control = list(trace = 1, rel.tol = 1e-9))
sprintf("%.3f", disc$estimates[c("logOR_adj.hat", "sigsq_p", "sigsq_m")])


# 1,000 trials with n = 686
n <- 686
trials <- 1000
set.seed(1)
s1.list <- list()
s1r.list <- list()
for (ii in 1: length(sigsq_p.vals)) {

  sigsq_p.ii <- sigsq_p.vals[ii]
  sigsq_m.ii <- sigsq_m.vals[ii]

  r_lr.naive <- matrix(NA, ncol = 12, nrow = trials)
  r_lr.full.p <- matrix(NA, ncol = 13, nrow = trials)
  r_lr.full.m <- matrix(NA, ncol = 13, nrow = trials)
  r_lr.full.b <- matrix(NA, ncol = 14, nrow = trials)
  r_lr.approx.p <- matrix(NA, ncol = 13, nrow = trials)
  r_lr.approx.m <- matrix(NA, ncol = 13, nrow = trials)
  r_lr.approx.b <- matrix(NA, ncol = 14, nrow = trials)
  r_disc.naive <- matrix(NA, ncol = 12, nrow = trials)
  r_disc.p <- matrix(NA, ncol = 13, nrow = trials)
  r_disc.m <- matrix(NA, ncol = 13, nrow = trials)
  r_disc.b <- matrix(NA, ncol = 14, nrow = trials)

  r2_lr.full.m <- matrix(NA, ncol = 13, nrow = trials)
  r2_lr.full.b <- matrix(NA, ncol = 14, nrow = trials)
  r2_lr.approx.m <- matrix(NA, ncol = 13, nrow = trials)
  r2_lr.approx.b <- matrix(NA, ncol = 14, nrow = trials)
  r2_disc.m <- matrix(NA, ncol = 13, nrow = trials)
  r2_disc.b <- matrix(NA, ncol = 14, nrow = trials)

  for (jj in 1: trials) {

    print(c(ii, jj))

    # Generate individual-level data
    c1 <- sample(size = n, x = age.vals, prob = age.probs, replace = TRUE)
    c2 <- rbinom(n = n, size = 1, prob = p_nw)
    c3 <- rbinom(n = n, size = 1, prob = p_smoke)
    x <- rnorm(n = n, mean = alphas[1] + alphas[2] * c1 + alphas[3] * c2 +
                 alphas[4] * c3, sd = sqrt(sigsq_x))
    p_y.x <- (1 + exp(-betas[1] - betas[2] * x - betas[3] * c1 - betas[4] * c2 -
                        betas[5] * c3))^(-1)
    y <- rbinom(n = n, size = 1, prob = p_y.x)
    dat.ind <- data.frame(y = y, x = x, c1 = c1, c2 = c2, c3 = c3)

    # Split into cases and controls
    locs.y1 <- which(y == 1)
    locs.y0 <- which(y == 0)
    n.y1 <- length(locs.y1)
    n.y0 <- length(locs.y0)
    dat.ind.y1 <- dat.ind[locs.y1, ]
    dat.ind.y0 <- dat.ind[locs.y0, ]

    # Create case/control pools
    n.y1pools.23 <- ceiling(n.y1 / 6)
    n.y1pools.1 <- n.y1 - n.y1pools.23 * 5
    dat.y1.p <- p.neighbors(dat = dat.ind.y1, pool.sizes = c(3, 2, 1),
                  n.pools = c(rep(n.y1pools.23, 2), n.y1pools.1))
    dat.y1.p$y_onezero <- 1

    n.y0pools.23 <- ceiling(n.y0 / 6)
    n.y0pools.1 <- n.y0 - n.y0pools.23 * 5
    dat.y0.p <- p.neighbors(dat = dat.ind.y0, pool.sizes = c(3, 2, 1),
                            n.pools = c(rep(n.y0pools.23, 2), n.y0pools.1))
    dat.y0.p$y_onezero <- 0

    # Create combined poolwise dataset
    dat.p <- rbind(dat.y1.p, dat.y0.p)

    # Add errors
    n.pools <- nrow(dat.p)
    dat.p$xtilde <-
      (dat.p$x / dat.p$g + rnorm(n = n.pools, sd = sqrt(sigsq_p.ii)) *
         ifelse(dat.p$g > 1, 1, 0) +
         rnorm(n = n.pools, sd = sqrt(sigsq_m.ii))) *
      dat.p$g
    locs.g1 <- which(dat.p$g == 1)
    locs.k2 <- sample(locs.g1, size = 30, replace = FALSE)
    xtilde.list <- list()
    for (kk in 1: n.pools) {
      if (kk %in% locs.k2) {
        xtilde.list[[kk]] <- c(dat.p$xtilde[kk], dat.p$x[kk] + rnorm(n = 1, sd = sqrt(sigsq_m.ii)))
      } else {
        xtilde.list[[kk]] <- dat.p$xtilde[kk]
      }
    }

    # Fit various models
    lr.naive <- p.logistic.xerrors(g = dat.p$g,
                                   y = dat.p$y_onezero,
                                   xtilde = dat.p$xtilde,
                                   c = dat.p[, c("c1", "c2", "c3")],
                                   error.type = "neither",
                                   estimate.var = FALSE,
                                   lower = c(rep(-Inf, 9), 1e-3),
                                   control = list(trace = 0, rel.tol = 1e-9))
    r_lr.naive[jj, ] <- c(lr.naive$theta.hat, lr.naive$aic, n.pools)


    # lr.full.p <- p.logistic.xerrors(g = dat.p$g,
    #                                 y = dat.p$y_onezero,
    #                                 xtilde = dat.p$xtilde,
    #                                 c = dat.p[, c("c1", "c2", "c3")],
    #                                 error.type = "processing",
    #                                 approx.integral = FALSE,
    #                                 integrate.tol = 1e-7,
    #                                 estimate.var = FALSE,
    #                                 lower = c(rep(-Inf, 9), rep(1e-3, 2)),
    #                                 control = list(trace = 1, rel.tol = 1e-9))
    # r_lr.full.p[jj, ] <- c(lr.full.p$theta.hat, lr.full.p$aic)
    #
    # lr.full.m <- p.logistic.xerrors(g = dat.p$g,
    #                                 y = dat.p$y_onezero,
    #                                 xtilde = dat.p$xtilde,
    #                                 c = dat.p[, c("c1", "c2", "c3")],
    #                                 error.type = "measurement",
    #                                 approx.integral = FALSE,
    #                                 integrate.tol = 1e-7,
    #                                 estimate.var = FALSE,
    #                                 lower = c(rep(-Inf, 9), rep(1e-3, 2)),
    #                                 control = list(trace = 1, rel.tol = 1e-9))
    # r_lr.full.m[jj, ] <- c(lr.full.m$theta.hat, lr.full.m$aic)
    #
    # lr.full.b <- p.logistic.xerrors(g = dat.p$g,
    #                                 y = dat.p$y_onezero,
    #                                 xtilde = dat.p$xtilde,
    #                                 c = dat.p[, c("c1", "c2", "c3")],
    #                                 error.type = "both",
    #                                 approx.integral = FALSE,
    #                                 integrate.tol = 1e-7,
    #                                 estimate.var = FALSE,
    #                                 lower = c(rep(-Inf, 9), rep(1e-3, 3)),
    #                                 control = list(trace = 1, rel.tol = 1e-9))
    # r_lr.full.b[jj, ] <- c(lr.full.b$theta.hat, lr.full.b$aic)

    lr.approx.p <- p.logistic.xerrors(g = dat.p$g,
                                      y = dat.p$y_onezero,
                                      xtilde = dat.p$xtilde,
                                      c = dat.p[, c("c1", "c2", "c3")],
                                      error.type = "processing",
                                      approx.integral = TRUE,
                                      estimate.var = FALSE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 0, rel.tol = 1e-9))
    r_lr.approx.p[jj, ] <- c(lr.approx.p$theta.hat, lr.approx.p$aic, n.pools)

    lr.approx.m <- p.logistic.xerrors(g = dat.p$g,
                                      y = dat.p$y_onezero,
                                      xtilde = dat.p$xtilde,
                                      c = dat.p[, c("c1", "c2", "c3")],
                                      error.type = "measurement",
                                      approx.integral = TRUE,
                                      estimate.var = FALSE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 0, rel.tol = 1e-9))
    r_lr.approx.m[jj, ] <- c(lr.approx.m$theta.hat, lr.approx.m$aic, n.pools)

    lr.approx.m2 <- p.logistic.xerrors(g = dat.p$g,
                                       y = dat.p$y_onezero,
                                       xtilde = xtilde.list,
                                       c = dat.p[, c("c1", "c2", "c3")],
                                       error.type = "measurement",
                                       approx.integral = TRUE,
                                       estimate.var = FALSE,
                                       lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                       control = list(trace = 0, rel.tol = 1e-9))
    r2_lr.approx.m[jj, ] <- c(lr.approx.m2$theta.hat, lr.approx.m$aic, n.pools)

    lr.approx.b <- p.logistic.xerrors(g = dat.p$g,
                                      y = dat.p$y_onezero,
                                      xtilde = dat.p$xtilde,
                                      c = dat.p[, c("c1", "c2", "c3")],
                                      error.type = "both",
                                      approx.integral = TRUE,
                                      estimate.var = FALSE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                      control = list(trace = 0, rel.tol = 1e-9))
    r_lr.approx.b[jj, ] <- c(lr.approx.b$theta.hat, lr.approx.b$aic, n.pools)

    lr.approx.b2 <- p.logistic.xerrors(g = dat.p$g,
                                       y = dat.p$y_onezero,
                                       xtilde = xtilde.list,
                                       c = dat.p[, c("c1", "c2", "c3")],
                                       error.type = "both",
                                       approx.integral = TRUE,
                                       estimate.var = FALSE,
                                       lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                       control = list(trace = 0, rel.tol = 1e-9))
    r2_lr.approx.b[jj, ] <- c(lr.approx.b2$theta.hat, lr.approx.b$aic, n.pools)


    disc.naive <- p.disc.xerrors(g = dat.p$g,
                                 y = dat.p$y,
                                 xtilde = dat.p$xtilde,
                                 c = dat.p[, c("c1", "c2", "c3")],
                                 error.type = "neither",
                                 lower = c(rep(-Inf, 5), 1e-3),
                                 control = list(trace = 0, rel.tol = 1e-9))
    r_disc.naive[jj, ] <- c(disc.naive$estimates, disc.naive$aic, n.pools)

    disc.p <- p.disc.xerrors(g = dat.p$g,
                             y = dat.p$y,
                             xtilde = dat.p$xtilde,
                             c = dat.p[, c("c1", "c2", "c3")],
                             error.type = "processing",
                             lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                             control = list(trace = 0, rel.tol = 1e-9))
    r_disc.p[jj, ] <- c(disc.p$estimates, disc.p$aic, n.pools)

    disc.m <- p.disc.xerrors(g = dat.p$g,
                             y = dat.p$y,
                             xtilde = dat.p$xtilde,
                             c = dat.p[, c("c1", "c2", "c3")],
                             error.type = "measurement",
                             lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                             control = list(trace = 0, rel.tol = 1e-9))
    r_disc.m[jj, ] <- c(disc.m$estimates, disc.m$aic, n.pools)

    disc.m2 <- p.disc.xerrors(g = dat.p$g,
                              y = dat.p$y,
                              xtilde = xtilde.list,
                              c = dat.p[, c("c1", "c2", "c3")],
                              error.type = "measurement",
                              lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                              control = list(trace = 0, rel.tol = 1e-9))
    r2_disc.m[jj, ] <- c(disc.m2$estimates, disc.m2$aic, n.pools)

    disc.b <- p.disc.xerrors(g = dat.p$g,
                             y = dat.p$y,
                             xtilde = dat.p$xtilde,
                             c = dat.p[, c("c1", "c2", "c3")],
                             error.type = "both",
                             lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                             control = list(trace = 0, rel.tol = 1e-9))
    r_disc.b[jj, ] <- c(disc.b$estimates, disc.b$aic, n.pools)

    disc.b2 <- p.disc.xerrors(g = dat.p$g,
                              y = dat.p$y,
                              xtilde = xtilde.list,
                              c = dat.p[, c("c1", "c2", "c3")],
                              error.type = "both",
                              lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                              control = list(trace = 0, rel.tol = 1e-9))
    r2_disc.b[jj, ] <- c(disc.b2$estimates, disc.b2$aic, n.pools)

  }

  # Add results to list
  s1.list[[ii]] <- list(r_lr.naive,
                        r_lr.full.p, r_lr.full.m, r_lr.full.b,
                        r_lr.approx.p, r_lr.approx.m, r_lr.approx.b,
                        r_disc.naive,
                        r_disc.p, r_disc.m, r_disc.b)
  s1r.list[[ii]] <- list(r2_lr.full.m, r2_lr.full.b,
                         r2_lr.approx.m, r2_lr.approx.b,
                         r2_disc.m, r2_disc.b)

}
save(s1.list, file = "sim1_list.rda")
save(s1r.list, file = "sim1r_list.rda")

# Scenario 1a

s1a.naive <- s1.list[[1]][[1]]
s1a.naive.means <- apply(s1a.naive, 2, mean)[c(1: 5, 10)]
sprintf("%.3f", s1a.naive.means)

# Insert full ML

s1a.lr.approx <- s1.list[[1]][[5]]
s1a.lr.approx.means <- apply(s1a.lr.approx, 2, mean)[c(1: 5, 10: 11)]
sprintf("%.3f", s1a.lr.approx.means)

s1a.disc <- s1.list[[1]][[9]]
s1a.disc.means <- apply(s1a.disc, 2, mean)[c(10, 7)]
sprintf("%.3f", s1a.disc.means)

sum(s1a.lr.approx[, 10] == 0.001)
sum(s1a.lr.approx[, 11] == 0.001)
sum(s1a.disc[, 7] == 0.001)

sprintf("%.3f", apply(s1a.lr.approx, 2, sd)[c(1: 5, 10: 11)])
sprintf("%.3f", apply(s1a.disc, 2, sd)[c(10, 7)])

s1a.lr.approx.n <- s1.list[[1]][[1]]
s1a.lr.approx.p <- s1.list[[1]][[5]]
s1a.lr.approx.m <- s1.list[[1]][[6]]
s1a.lr.approx.b <- s1.list[[1]][[7]]
aic.vals <- cbind(s1a.lr.approx.n[, 11], s1a.lr.approx.p[, 12], s1a.lr.approx.m[, 12], s1a.lr.approx.b[, 13])
table(apply(aic.vals, 1, which.min))


# Scenario 1b without replicates

s1b.naive <- s1.list[[2]][[1]]
s1b.naive.means <- apply(s1b.naive, 2, mean)[c(1: 5, 10)]
sprintf("%.3f", s1b.naive.means)

# Insert full ML

s1b.lr.approx <- s1.list[[2]][[6]]
s1b.lr.approx.means <- apply(s1b.lr.approx, 2, mean)[c(1: 5, 10: 11)]
sprintf("%.3f", s1b.lr.approx.means)

s1b.disc <- s1.list[[2]][[10]]
s1b.disc.means <- apply(s1b.disc, 2, mean)[c(10, 7)]
sprintf("%.3f", s1b.disc.means)

sum(s1b.lr.approx[, 10] == 0.001)
sum(s1b.lr.approx[, 11] == 0.001)
sum(s1b.disc[, 7] == 0.001)

sprintf("%.3f", apply(s1b.lr.approx, 2, sd)[c(1: 5, 10: 11)])
sprintf("%.3f", apply(s1b.disc, 2, sd)[c(10, 7)])

s1b.lr.approx.n <- s1.list[[2]][[1]]
s1b.lr.approx.p <- s1.list[[2]][[5]]
s1b.lr.approx.m <- s1.list[[2]][[6]]
s1b.lr.approx.b <- s1.list[[2]][[7]]
aic.vals <- cbind(s1b.lr.approx.n[, 11], s1b.lr.approx.p[, 12], s1b.lr.approx.m[, 12], s1b.lr.approx.b[, 13])
table(apply(aic.vals, 1, which.min))

# Scenario 1b with replicates

# Insert full ML

s1b.lr.approx <- s1r.list[[2]][[3]]
s1b.lr.approx.means <- apply(s1b.lr.approx, 2, mean)[c(1: 5, 10: 11)]
sprintf("%.3f", s1b.lr.approx.means)

s1b.disc <- s1r.list[[2]][[5]]
s1b.disc.means <- apply(s1b.disc, 2, mean)[c(10, 7)]
sprintf("%.3f", s1b.disc.means)

sum(s1b.lr.approx[, 10] == 0.001)
sum(s1b.lr.approx[, 11] == 0.001)
sum(s1b.disc[, 7] == 0.001)

sprintf("%.3f", apply(s1b.lr.approx, 2, sd)[c(1: 5, 10: 11)])
sprintf("%.3f", apply(s1b.disc, 2, sd)[c(10, 7)])

s1b.lr.approx.m <- s1r.list[[2]][[3]]
s1b.lr.approx.b <- s1r.list[[2]][[4]]
aic.vals <- cbind(s1b.lr.approx.m[, 12], s1b.lr.approx.b[, 13])
table(apply(aic.vals, 1, which.min))

# Scenario 1c, no replicates

s1c.naive <- s1.list[[3]][[1]]
s1c.naive.means <- apply(s1c.naive, 2, mean)[c(1: 5, 10)]
sprintf("%.3f", s1c.naive.means)

# Insert full ML

s1c.lr.approx <- s1.list[[3]][[7]]
s1c.lr.approx.means <- apply(s1c.lr.approx, 2, mean)[c(1: 5, 10: 12)]
sprintf("%.3f", s1c.lr.approx.means)
s1c.lr.approx.medians <- apply(s1c.lr.approx, 2, median)[c(1: 5, 10: 12)]
sprintf("%.3f", s1c.lr.approx.medians)

s1c.disc <- s1.list[[3]][[11]]
s1c.disc.means <- apply(s1c.disc, 2, mean)[c(11, 7, 8)]
sprintf("%.3f", s1c.disc.means)
s1c.disc.medians <- apply(s1c.disc, 2, median)[c(11, 7, 8)]
sprintf("%.3f", s1c.disc.medians)

sum(s1c.lr.approx[, 10] == 0.001)
sum(s1c.lr.approx[, 11] == 0.001)
sum(s1c.lr.approx[, 12] == 0.001)

sum(s1c.disc[, 6] == 0.001)
sum(s1c.disc[, 7] == 0.001)
sum(s1c.disc[, 8] == 0.001)

# Scenario 1c, with replicates

# Insert full ML

s1c.lr.approx <- s1r.list[[3]][[4]]
s1c.lr.approx.means <- apply(s1c.lr.approx, 2, mean)[c(1: 5, 10: 12)]
sprintf("%.3f", s1c.lr.approx.means)

s1c.disc <- s1r.list[[3]][[6]]
s1c.disc.means <- apply(s1c.disc, 2, mean)[c(11, 7, 8)]
sprintf("%.3f", s1c.disc.means)
s1c.disc.medians <- apply(s1c.disc, 2, median)[c(11, 7, 8)]
sprintf("%.3f", s1c.disc.medians)

sum(s1c.lr.approx[, 10] == 0.001)
sum(s1c.lr.approx[, 11] == 0.001)
sum(s1c.lr.approx[, 12] == 0.001)

sum(s1c.disc[, 6] == 0.001)
sum(s1c.disc[, 7] == 0.001)
sum(s1c.disc[, 8] == 0.001)

s1c.lr.approx.medians <- apply(s1c.lr.approx, 2, median)[c(1: 5, 10: 12)]
sprintf("%.3f", s1c.lr.approx.medians)


s1c.disc.medians <- apply(s1c.disc, 2, median)[c(11, 7, 8)]
sprintf("%.3f", s1c.disc.medians)





s1a.lr.naive.bias <- c(betas, alphas, sigsq_x) - apply(s1.list[[1]][[1]], 2, mean)[-11]
s1a.lr.naive.sd <- apply(s1.list[[1]][[1]], 2, sd)
paste(sprintf("%.2f", s1a.lr.naive.bias), " (",
      sprintf("%.2f", s1a.lr.naive.sd), ")", sep = "")

paste(sprintf(c(betas, alphas, sigsq_x, 0) - apply(s1.list[[1]][[1]], 2, mean)



  # Create list of xtilde values
  xtilde.ii <- apply(xtilde.ii, 1, function(x) list(x[1: length(x)]))
  xtilde.ii <- lapply(xtilde.ii, unlist)

  # Record g, y, xtilde, and C
  g <- c(g, rep(pool.sizes.ii, nrow(dat.ii)))
  y <- c(y, dat.ii$y_onezero)
  xtilde <- c(xtilde, xtilde.ii)
  c <- c(c, dat.ii$c)

}

abc <- p.logistic.xerrors(g = g, y = y, xtilde = unlist(xtilde), c = as.matrix(c, ncol = 1),
                          error.type = "measurement", control = list(trace = 1))










# Table 2 using old CPP dataset ---------------------------------------------

cpp.pooled$mcp1_10x <- cpp.pooled$mcp1 * 10

# USING OLD FUNCTIONS WITH ERROR IN G

# Neither error
lr.full.n <- p.logistic.xerrors.old(g = cpp.pooled$g,
                                    y = cpp.pooled$SA_onezero,
                                    xtilde = cpp.pooled$mcp1_10x,
                                    c = cpp.pooled[, c("race", "smoke")],
                                    error.type = "neither",
                                    estimate.var = TRUE,
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.n$aic), sep = "")

disc.n <- p.disc.xerrors.old(g = cpp.pooled$g,
                             y = cpp.pooled$SA,
                             xtilde = cpp.pooled$mcp1_10x,
                             c = cpp.pooled[, c("race", "smoke")],
                             error.type = "neither",
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.n$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.n$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.n$aic), sep = "")

gamma.n <- p.logistic.xerrors.agamma.old(g = cpp.pooled$g,
                                         y = cpp.pooled$SA_onezero,
                                         xtilde = cpp.pooled$mcp1_10x,
                                         c = racesmoke.list,
                                         error.type = "neither",
                                         estimate.var = TRUE,
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.n$aic), sep = "")

# PE only
lr.full.p <- p.logistic.xerrors.old(g = cpp.pooled$g,
                                    y = cpp.pooled$SA_onezero,
                                    xtilde = cpp.pooled$mcp1_10x,
                                    c = cpp.pooled[, c("race", "smoke")],
                                    error.type = "processing",
                                    approx.integral = FALSE,
                                    integrate.tol = 1e-9,
                                    estimate.var = TRUE,
                                    lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.p$aic), sep = "")

lr.approx.p <- p.logistic.xerrors.old(g = cpp.pooled$g,
                                      y = cpp.pooled$SA_onezero,
                                      xtilde = cpp.pooled$mcp1_10x,
                                      c = cpp.pooled[, c("race", "smoke")],
                                      error.type = "processing",
                                      approx.integral = TRUE,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.p$aic), sep = "")

disc.p <- p.disc.xerrors.old(g = cpp.pooled$g,
                             y = cpp.pooled$SA,
                             xtilde = cpp.pooled$mcp1_10x,
                             c = cpp.pooled[, c("race", "smoke")],
                             error.type = "processing",
                             lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.p$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.p$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.p$aic), sep = "")

gamma.p <- p.logistic.xerrors.agamma.old(g = cpp.pooled$g,
                                         y = cpp.pooled$SA_onezero,
                                         xtilde = cpp.pooled$mcp1_10x,
                                         c = racesmoke.list,
                                         error.type = "processing",
                                         integrate.tol = 1e-7,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.p$aic), sep = "")

# ME only
lr.full.m <- p.logistic.xerrors.old(g = cpp.pooled$g,
                                    y = cpp.pooled$SA_onezero,
                                    xtilde = cpp.pooled$mcp1_10x,
                                    c = cpp.pooled[, c("race", "smoke")],
                                    error.type = "measurement",
                                    approx.integral = FALSE,
                                    integrate.tol = 1e-6,
                                    estimate.var = TRUE,
                                    lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m$aic), sep = "")

lr.approx.m <- p.logistic.xerrors.old(g = cpp.pooled$g,
                                      y = cpp.pooled$SA_onezero,
                                      xtilde = cpp.pooled$mcp1_10x,
                                      c = cpp.pooled[, c("race", "smoke")],
                                      error.type = "measurement",
                                      approx.integral = TRUE,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m$aic), sep = "")

disc.m <- p.disc.xerrors.old(g = cpp.pooled$g,
                             y = cpp.pooled$SA,
                             xtilde = cpp.pooled$mcp1_10x,
                             c = cpp.pooled[, c("race", "smoke")],
                             error.type = "measurement",
                             lower = c(rep(-Inf, 4), rep(1e-3, 2)),
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m$aic), sep = "")

gamma.m <- p.logistic.xerrors.agamma.old(g = cpp.pooled$g,
                                         y = cpp.pooled$SA_onezero,
                                         xtilde = cpp.pooled$mcp1_10x,
                                         c = racesmoke.list,
                                         error.type = "measurement",
                                         integrate.tol = 1e-7,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m$aic), sep = "")

# Both PE and ME
gamma.b <- p.logistic.xerrors.agamma.old(g = cpp.pooled$g,
                                         y = cpp.pooled$SA_onezero,
                                         xtilde = cpp.pooled$mcp1_10x,
                                         c = racesmoke.list,
                                         error.type = "both",
                                         integrate.tol = 1e-7,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b$aic), sep = "")

# USING CORRECTED FUNCTIONS

# Neither error
lr.full.n <- p.logistic.xerrors(g = cpp.pooled$g,
                                y = cpp.pooled$SA_onezero,
                                xtilde = cpp.pooled$mcp1_10x,
                                c = cpp.pooled[, c("race", "smoke")],
                                error.type = "neither",
                                estimate.var = TRUE,
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.n$aic), sep = "")

disc.n <- p.disc.xerrors(g = cpp.pooled$g,
                         y = cpp.pooled$SA,
                         xtilde = cpp.pooled$mcp1_10x,
                         c = cpp.pooled[, c("race", "smoke")],
                         error.type = "neither",
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.n$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.n$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.n$aic), sep = "")

# PE only
lr.full.p <- p.logistic.xerrors(g = cpp.pooled$g,
                                y = cpp.pooled$SA_onezero,
                                xtilde = cpp.pooled$mcp1_10x,
                                c = cpp.pooled[, c("race", "smoke")],
                                error.type = "processing",
                                approx.integral = FALSE,
                                integrate.tol = 1e-9,
                                estimate.var = TRUE,
                                lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.p$aic), sep = "")

lr.approx.p <- p.logistic.xerrors(g = cpp.pooled$g,
                                  y = cpp.pooled$SA_onezero,
                                  xtilde = cpp.pooled$mcp1_10x,
                                  c = cpp.pooled[, c("race", "smoke")],
                                  error.type = "processing",
                                  approx.integral = TRUE,
                                  estimate.var = TRUE,
                                  lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                  control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.p$aic), sep = "")

disc.p <- p.disc.xerrors(g = cpp.pooled$g,
                         y = cpp.pooled$SA,
                         xtilde = cpp.pooled$mcp1_10x,
                         c = cpp.pooled[, c("race", "smoke")],
                         error.type = "processing",
                         lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.p$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.p$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.p$aic), sep = "")

gamma.p <- p.logistic.xerrors.agamma(g = cpp.pooled$g,
                                     y = cpp.pooled$SA_onezero,
                                     xtilde = cpp.pooled$mcp1_10x,
                                     c = racesmoke.list,
                                     error.type = "processing",
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.p$aic), sep = "")

# ME only
lr.full.m <- p.logistic.xerrors(g = cpp.pooled$g,
                                y = cpp.pooled$SA_onezero,
                                xtilde = cpp.pooled$mcp1_10x,
                                c = cpp.pooled[, c("race", "smoke")],
                                error.type = "measurement",
                                approx.integral = FALSE,
                                integrate.tol = 1e-6,
                                estimate.var = TRUE,
                                lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m$aic), sep = "")

lr.approx.m <- p.logistic.xerrors(g = cpp.pooled$g,
                                  y = cpp.pooled$SA_onezero,
                                  xtilde = cpp.pooled$mcp1_10x,
                                  c = cpp.pooled[, c("race", "smoke")],
                                  error.type = "measurement",
                                  approx.integral = TRUE,
                                  estimate.var = TRUE,
                                  lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                  control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m$aic), sep = "")

disc.m <- p.disc.xerrors(g = cpp.pooled$g,
                         y = cpp.pooled$SA,
                         xtilde = cpp.pooled$mcp1_10x,
                         c = cpp.pooled[, c("race", "smoke")],
                         error.type = "measurement",
                         lower = c(rep(-Inf, 4), rep(1e-3, 2)),
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m$aic), sep = "")

gamma.m <- p.logistic.xerrors.agamma(g = cpp.pooled$g,
                                     y = cpp.pooled$SA_onezero,
                                     xtilde = cpp.pooled$mcp1_10x,
                                     c = racesmoke.list,
                                     error.type = "measurement",
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m$aic), sep = "")

# Both
gamma.b <- p.logistic.xerrors.agamma(g = cpp.pooled$g,
                                     y = cpp.pooled$SA_onezero,
                                     xtilde = cpp.pooled$mcp1_10x,
                                     c = racesmoke.list,
                                     error.type = "both",
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 7), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b$aic), sep = "")




# Table 2 using new CPP dataset -------------------------------------------



# Table 2

# USING OLD FUNCTIONS WITH ERROR IN G

# No replicates, neither error
lr.full.n <- p.logistic.xerrors.old(g = cpp.df$g,
                                    y = cpp.df$SA_onezero,
                                    xtilde = cpp.df$mcp1_10x,
                                    c = cpp.df[, c("m_age", "nw", "smoke")],
                                    error.type = "neither",
                                    approx.integral = FALSE,
                                    estimate.var = TRUE,
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.n$aic), sep = "")

disc.n <- p.disc.xerrors.old(g = cpp.df$g,
                             y = cpp.df$SA,
                             xtilde = cpp.df$mcp1_10x,
                             c = cpp.df[, c("m_age", "nw", "smoke")],
                             error.type = "neither",
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.n$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.n$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.n$aic), sep = "")

gamma.n <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                         y = cpp.df$SA_onezero,
                                         xtilde = cpp.df$mcp1_10x,
                                         c = c.list,
                                         error.type = "neither",
                                         estimate.var = TRUE,
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.n$aic), sep = "")

# No replicates, PE only
lr.full.p <- p.logistic.xerrors.old(g = cpp.df$g,
                                    y = cpp.df$SA_onezero,
                                    xtilde = cpp.df$mcp1_10x,
                                    c = cpp.df[, c("m_age", "nw", "smoke")],
                                    error.type = "processing",
                                    approx.integral = FALSE,
                                    integrate.tol = 1e-7,
                                    estimate.var = TRUE,
                                    lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.p$aic), sep = "")

lr.approx.p <- p.logistic.xerrors.old(g = cpp.df$g,
                                      y = cpp.df$SA_onezero,
                                      xtilde = cpp.df$mcp1_10x,
                                      c = cpp.df[, c("m_age", "nw", "smoke")],
                                      error.type = "processing",
                                      approx.integral = TRUE,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.p$aic), sep = "")

disc.p <- p.disc.xerrors.old(g = cpp.df$g,
                             y = cpp.df$SA,
                             xtilde = cpp.df$mcp1_10x,
                             c = cpp.df[, c("m_age", "nw", "smoke")],
                             error.type = "processing",
                             lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.p$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.p$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.p$aic), sep = "")

gamma.p <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                         y = cpp.df$SA_onezero,
                                         xtilde = cpp.df$mcp1_10x,
                                         c = c.list,
                                         error.type = "processing",
                                         integrate.tol = 1e-7,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.p$aic), sep = "")

# No replicates, ME only
lr.full.m <- p.logistic.xerrors.old(g = cpp.df$g,
                                    y = cpp.df$SA_onezero,
                                    xtilde = cpp.df$mcp1_10x,
                                    c = cpp.df[, c("m_age", "nw", "smoke")],
                                    error.type = "measurement",
                                    approx.integral = FALSE,
                                    integrate.tol = 1e-7,
                                    estimate.var = TRUE,
                                    lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                    control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m$aic), sep = "")

lr.approx.m <- p.logistic.xerrors.old(g = cpp.df$g,
                                      y = cpp.df$SA_onezero,
                                      xtilde = cpp.df$mcp1_10x,
                                      c = cpp.df[, c("m_age", "nw", "smoke")],
                                      error.type = "measurement",
                                      approx.integral = TRUE,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m$aic), sep = "")

disc.m <- p.disc.xerrors.old(g = cpp.df$g,
                             y = cpp.df$SA,
                             xtilde = cpp.df$mcp1_10x,
                             c = cpp.df[, c("m_age", "nw", "smoke")],
                             error.type = "measurement",
                             lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                             control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m$aic), sep = "")

gamma.m <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                         y = cpp.df$SA_onezero,
                                         xtilde = cpp.df$mcp1_10x,
                                         c = c.list,
                                         error.type = "measurement",
                                         integrate.tol = 1e-8,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m$aic), sep = "")

# No replicates, both
gamma.b <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                         y = cpp.df$SA_onezero,
                                         xtilde = cpp.df$mcp1_10x,
                                         c = c.list,
                                         error.type = "both",
                                         integrate.tol = 1e-7,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b$aic), sep = "")

# Replicates, ME only
lr.full.m2 <- p.logistic.xerrors.old(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = mcp1_10x.reps,
                                     c = cpp.df[, c("m_age", "nw", "smoke")],
                                     error.type = "measurement",
                                     approx.integral = FALSE,
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m2$aic), sep = "")

lr.approx.m2 <- p.logistic.xerrors.old(g = cpp.df$g,
                                       y = cpp.df$SA_onezero,
                                       xtilde = mcp1_10x.reps,
                                       c = cpp.df[, c("m_age", "nw", "smoke")],
                                       error.type = "measurement",
                                       approx.integral = TRUE,
                                       lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                       estimate.var = TRUE,
                                       control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m2$aic), sep = "")

disc.m2 <- p.disc.xerrors.old(g = cpp.df$g,
                              y = cpp.df$SA,
                              xtilde = mcp1_10x.reps,
                              c = cpp.df[, c("m_age", "nw", "smoke")],
                              error.type = "measurement",
                              lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                              control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m2$aic), sep = "")

gamma.m2 <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                         y = cpp.df$SA_onezero,
                                         xtilde = mcp1_10x.reps,
                                         c = c.list,
                                         error.type = "measurement",
                                         integrate.tol = 1e-8,
                                         estimate.var = TRUE,
                                         lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m2$aic), sep = "")

# Replicates, both
lr.full.b2 <- p.logistic.xerrors.old(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = mcp1_10x.reps,
                                     c = cpp.df[, c("m_age", "nw", "smoke")],
                                     error.type = "both",
                                     approx.integral = FALSE,
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.b2$aic), sep = "")

lr.approx.b2 <- p.logistic.xerrors.old(g = cpp.df$g,
                                       y = cpp.df$SA_onezero,
                                       xtilde = mcp1_10x.reps,
                                       c = cpp.df[, c("m_age", "nw", "smoke")],
                                       error.type = "both",
                                       approx.integral = TRUE,
                                       estimate.var = TRUE,
                                       lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                       control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.b2$aic), sep = "")

disc.b2 <- p.disc.xerrors.old(g = cpp.df$g,
                              y = cpp.df$SA,
                              xtilde = mcp1_10x.reps,
                              c = cpp.df[, c("m_age", "nw", "smoke")],
                              error.type = "both",
                              lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                              control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.b2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.b2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.b2$aic), sep = "")

gamma.b2 <- p.logistic.xerrors.agamma.old(g = cpp.df$g,
                                          y = cpp.df$SA_onezero,
                                          xtilde = mcp1_10x.reps,
                                          c = c.list,
                                          error.type = "both",
                                          integrate.tol = 1e-8,
                                          estimate.var = TRUE,
                                          lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b2$aic), sep = "")

# USING CORRECTED FUNCTIONS

# No replicates, neither error
lr.full.n <- p.logistic.xerrors(g = cpp.df$g,
                                y = cpp.df$SA_onezero,
                                xtilde = cpp.df$mcp1_10x,
                                c = cpp.df[, c("m_age", "nw", "smoke")],
                                error.type = "neither",
                                approx.integral = FALSE,
                                estimate.var = TRUE,
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.n$aic), sep = "")

disc.n <- p.disc.xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = cpp.df$mcp1_10x,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         error.type = "measurement",
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.n$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.n$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.n$aic), sep = "")

gamma.n <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = cpp.df$mcp1_10x,
                                     c = c.list,
                                     error.type = "neither",
                                     estimate.var = TRUE,
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.n$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.n$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.n$aic), sep = "")

# No replicates, PE only
lr.full.p <- p.logistic.xerrors(g = cpp.df$g,
                                y = cpp.df$SA_onezero,
                                xtilde = cpp.df$mcp1_10x,
                                c = cpp.df[, c("m_age", "nw", "smoke")],
                                error.type = "processing",
                                approx.integral = FALSE,
                                integrate.tol = 1e-7,
                                estimate.var = TRUE,
                                lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.p$aic), sep = "")

lr.approx.p <- p.logistic.xerrors(g = cpp.df$g,
                                  y = cpp.df$SA_onezero,
                                  xtilde = cpp.df$mcp1_10x,
                                  c = cpp.df[, c("m_age", "nw", "smoke")],
                                  error.type = "processing",
                                  approx.integral = TRUE,
                                  estimate.var = TRUE,
                                  lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.p$aic), sep = "")

disc.p <- p.disc.xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = cpp.df$mcp1_10x,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         error.type = "processing",
                         lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.p$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.p$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.p$aic), sep = "")

gamma.p <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = cpp.df$mcp1_10x,
                                     c = c.list,
                                     error.type = "processing",
                                     integrate.tol = 1e-7,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.p$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.p$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.p$aic), sep = "")

# No replicates, ME only
lr.full.m <- p.logistic.xerrors(g = cpp.df$g,
                                y = cpp.df$SA_onezero,
                                xtilde = cpp.df$mcp1_10x,
                                c = cpp.df[, c("m_age", "nw", "smoke")],
                                error.type = "measurement",
                                approx.integral = FALSE,
                                integrate.tol = 1e-8,
                                estimate.var = TRUE,
                                lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m$aic), sep = "")

lr.approx.m <- p.logistic.xerrors(g = cpp.df$g,
                                  y = cpp.df$SA_onezero,
                                  xtilde = cpp.df$mcp1_10x,
                                  c = cpp.df[, c("m_age", "nw", "smoke")],
                                  error.type = "measurement",
                                  approx.integral = TRUE,
                                  estimate.var = TRUE,
                                  lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                  control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m$aic), sep = "")

disc.m <- p.disc.xerrors(g = cpp.df$g,
                         y = cpp.df$SA,
                         xtilde = cpp.df$mcp1_10x,
                         c = cpp.df[, c("m_age", "nw", "smoke")],
                         error.type = "measurement",
                         lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                         control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m$aic), sep = "")

gamma.m <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = cpp.df$mcp1_10x,
                                     c = c.list,
                                     error.type = "measurement",
                                     integrate.tol = 1e-8,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m$aic), sep = "")

# No replicates, both
gamma.b <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                     y = cpp.df$SA_onezero,
                                     xtilde = cpp.df$mcp1_10x,
                                     c = c.list,
                                     error.type = "both",
                                     integrate.tol = 1e-8,
                                     estimate.var = TRUE,
                                     lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                     control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b$aic), sep = "")

# Replicates, ME only
lr.full.m2 <- p.logistic.xerrors(g = cpp.df$g,
                                 y = cpp.df$SA_onezero,
                                 xtilde = mcp1_10x.reps,
                                 c = cpp.df[, c("m_age", "nw", "smoke")],
                                 error.type = "measurement",
                                 approx.integral = FALSE,
                                 integrate.tol = 1e-8,
                                 estimate.var = TRUE,
                                 lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                 control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.m2$aic), sep = "")

lr.approx.m2 <- p.logistic.xerrors(g = cpp.df$g,
                                   y = cpp.df$SA_onezero,
                                   xtilde = mcp1_10x.reps,
                                   c = cpp.df[, c("m_age", "nw", "smoke")],
                                   error.type = "measurement",
                                   approx.integral = TRUE,
                                   lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                   estimate.var = TRUE,
                                   control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.m2$aic), sep = "")

disc.m2 <- p.disc.xerrors(g = cpp.df$g,
                          y = cpp.df$SA,
                          xtilde = mcp1_10x.reps,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          error.type = "measurement",
                          lower = c(rep(-Inf, 5), rep(1e-3, 2)),
                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.m2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.m2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.m2$aic), sep = "")

gamma.m2 <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                      y = cpp.df$SA_onezero,
                                      xtilde = mcp1_10x.reps,
                                      c = c.list,
                                      error.type = "measurement",
                                      integrate.tol = 1e-8,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 2)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.m2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.m2$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.m2$aic), sep = "")

# Replicates, both
lr.full.b2 <- p.logistic.xerrors(g = cpp.df$g,
                                 y = cpp.df$SA_onezero,
                                 xtilde = mcp1_10x.reps,
                                 c = cpp.df[, c("m_age", "nw", "smoke")],
                                 error.type = "both",
                                 approx.integral = FALSE,
                                 integrate.tol = 1e-8,
                                 estimate.var = TRUE,
                                 lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                 control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.full.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.full.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.full.b2$aic), sep = "")

lr.approx.b2 <- p.logistic.xerrors(g = cpp.df$g,
                                   y = cpp.df$SA_onezero,
                                   xtilde = mcp1_10x.reps,
                                   c = cpp.df[, c("m_age", "nw", "smoke")],
                                   error.type = "both",
                                   approx.integral = TRUE,
                                   estimate.var = TRUE,
                                   lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                   control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", lr.approx.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(lr.approx.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", lr.approx.b2$aic), sep = "")

disc.b2 <- p.disc.xerrors(g = cpp.df$g,
                          y = cpp.df$SA,
                          xtilde = mcp1_10x.reps,
                          c = cpp.df[, c("m_age", "nw", "smoke")],
                          error.type = "both",
                          lower = c(rep(-Inf, 5), rep(1e-3, 3)),
                          control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", disc.b2$estimates["logOR_adj.hat"]), " (",
      sprintf("%.3f", sqrt(disc.b2$estimates["logOR_adj.var"])), "), ",
      sprintf("%.1f", disc.b2$aic), sep = "")

gamma.b2 <- p.logistic.xerrors.agamma(g = cpp.df$g,
                                      y = cpp.df$SA_onezero,
                                      xtilde = mcp1_10x.reps,
                                      c = c.list,
                                      error.type = "both",
                                      integrate.tol = 1e-8,
                                      estimate.var = TRUE,
                                      lower = c(rep(-Inf, 9), rep(1e-3, 3)),
                                      control = list(trace = 1, rel.tol = 1e-9))
paste(sprintf("%.3f", gamma.b2$theta.hat[2]), " (",
      sprintf("%.3f", sqrt(gamma.b2$theta.var[2, 2])), "), ",
      sprintf("%.1f", gamma.b2$aic), sep = "")














t1.or_ci <-
fit.table1$theta.hat



# Look at replicates
k <- sapply(mcp1.reps, length)
table(k)
table(cpp.df$g, k)

# Randomly select 30 replicates to keep; for others, just use first value.



table(cpp.df$g)
apply(cpp.df, 2, function(x) sum(is.na(x)))
locs <- ! is.na(cpp.df$nw) & ! is.na(cpp.df$smoke)
cpp.df <- subset(cpp.df, subset = locs)
mcp1.reps <- mcp1.reps[locs]
table(cpp.df$g)

# Covariates associated with SA
fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$mcp1)
fit1

fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$mcp1_10x)
fit1


fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$smoke)
fit1

fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$nw)
fit1

fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$m_age)
fit1

fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df$g_age,
                   method = "ml")
fit1


# Exploratory analysis
k <- sapply(mcp1.reps, length)

locs.g1k2 <- which(cpp.df$g == 1 & k == 2)
rep1 <- sapply(mcp1.reps[locs.g1k2], function(x) x[1])
rep2 <- sapply(mcp1.reps[locs.g1k2], function(x) x[2])
plot(rep1, rep2)
cor(rep1, rep2)

locs.g2k2 <- which(cpp.df$g == 2 & k == 2)
rep1 <- sapply(mcp1.reps[locs.g2k2], function(x) x[1])
rep2 <- sapply(mcp1.reps[locs.g2k2], function(x) x[2])
plot(rep1, rep2)
cor(rep1, rep2)

fit1 <- p.logistic(g = cpp.df$g,
                   y = cpp.df$SA_onezero,
                   x = cpp.df[, c("mcp1", "nw", "smoke")],
                   method = "ml")
fit1


mcp1.reps.2 <- mcp1.reps[sapply(mcp1.reps, length) == 2]
rep1 <- sapply(mcp1.reps.2, function(x) x[1])
rep2 <- sapply(mcp1.reps.2, function(x) x[2])
plot(rep1, rep2)
cor(rep1, rep2)


cor(cpp.df)

sapply(mcp1.reps, length)
sapply(mcp1.reps, length)[locs]

cpp.df <- subset(cpp.df, subset = ! is.na(black) & ! is.na(smoke))
table(cpp.df$g)


# Statistical setup (comments) --------------------------------------------

# Variables:

# Y = Incident pregnancy
# X = Low Vit. D (< 30 ng/mL)
# Z = Caloric intake (100-kcal)
# C1 = Age
# C2 = Obese
# D = Fatty acid


# Setup for ML/RC:

# TDM: E(Y) = beta_0 + beta_x X + beta_c1 C1 + beta_c2 C2 + beta_z Z
# MEM: E(Z) = alpha_0 + alpha_x X + alpha_c1 C1 + alpha_c2 C2 + alpha_d^T D


# Setup for PSC:

# e(X_GS) = P(X = 1 | C1, C2, Z)
# e(X_EP) = P(X = 1 | C1, C2)
# E[e(X_GS)] = lambda_0 + lambda_x X + lambda_P e(X_EP)





# Clear workspace, load packages, load datasets ---------------------------

rm(list = ls())
library("sas7bdat")
library("dvmisc")
library("tab")
library("pROC")
setwd("C:/Users/Dane/Google Drive/Documents/Research/Dissertation/nichd_data/data")
biocycle <- read.sas7bdat(file = "biocycle_for_dane.sas7bdat")
eager <- read.sas7bdat(file = "eager_data_for_dane1.sas7bdat")
setwd("C:/Users/Dane/Google Drive/Documents/Research/Dissertation/paper1/nichd_analysis")





# EAGeR data prep and exploratory analysis ---------------------------------------------------------

# Subset who did not withdraw early (1228 to 1088)
dim(eager)
eager <- subset(eager, statusNEW != "withdrawal")
dim(eager)

# Outcome data
table(eager$statusNEW)  # 5 levels
table(eager$anyloss)    # 2 levels
table(eager$PPT1_comp)  # Just 1's or missing

# Sunni e-mail 7/21/16: For PPT1_comp, missing's can be taken to mean no
# positive pregnancy test. But may want to exclude women who withdrew early.

# Create pregtest variable that is 1 if PPT_comp is 1, and 0 if PPT_comp is missing
eager$pregtest <- 0
eager$pregtest[eager$PPT1_comp == 1] <- 1
table(eager$pregtest)
mean(eager$pregtest)

# Exclude if vitamin D is missing (1088 to 1055)
sum(is.na(eager$VitDngmL))
dim(eager)
eager <- subset(eager, !is.na(VitDngmL))
dim(eager)

# Rename vitamin D variable, and create 10-ng and "low" versions of it
eager$vitd <- eager$VitDngmL
eager$vitd.10 <- eager$vitd / 10
eager$vitd.below20 <- ifelse(eager$vitd < 20, 1, 0)
eager$vitd.below30 <- ifelse(eager$vitd < 30, 1, 0)

# Create age variables
sum(is.na(eager$age))
range(eager$age)
eager$age.30plus <- ifelse(eager$age >= 30, 1, 0)
eager$age.35plus <- ifelse(eager$age >= 35, 1, 0)
eager$age.cat3 <- cut(eager$age, breaks = c(18, 30, 35, 41), include.lowest = T, right = F)
eager$age.cat4 <- cut(eager$age, breaks = c(18, 25, 30, 35, 41), include.lowest = T, right = F)
table(eager$age.30plus)
table(eager$age.35plus)
table(eager$age.cat3)
table(eager$age.cat4)

# Exclude if BMI is missing (1055 to 1041)
sum(is.na(eager$BMI))
dim(eager)
eager <- subset(eager, !is.na(BMI))
dim(eager)

# Create BMI variables
eager$bmi <- eager$BMI
eager$overweight <- ifelse(eager$bmi >= 25, 1, 0)
eager$obese <- ifelse(eager$bmi >= 30, 1, 0)
eager$bmi.cat3 <- bmi3(eager$bmi)
eager$bmi.cat4 <- bmi4(eager$bmi)
table(eager$overweight)
table(eager$obese)
table(eager$bmi.cat3)
table(eager$bmi.cat4)

# Education recode
table(eager$highschool)
eager$educ.f <- factor(eager$highschool, levels = c(1, 0), labels = c("High school or less", "Post-secondary"))
table(eager$educ.f)

# Income recode
sum(is.na(eager$DMGv34))
table(eager$DMGv34)
eager$income.f <- factor(eager$DMGv34, levels = 1: 5,
                         labels = c("(0, $20k)", "[$20k, $40k)", "[$40k, $75k)", "[$75k, $100k)", "[$100k, Inf)"))
table(eager$income.f)

# Alcohol intake recode
sum(is.na(eager$Alcohol_Intensity))
table(eager$Alcohol_Intensity)
eager$alcohol.f <- cut(eager$Alcohol_Intensity, breaks = c(0, 1, 2, 4), include.lowest = TRUE, right = FALSE,
                       labels = c("Never", "< 1x/month", ">= 1x/month"))
table(eager$alcohol.f)

# Smoking recode
sum(is.na(eager$smoke))
table(eager$smoke)
sum(eager$smoke == "")
eager$smoke[eager$smoke == ""] <- NA
eager$smoking.f <- NA
eager$smoking.f[eager$smoke == "Never"] <- "Non-smoker"
eager$smoking.f[eager$smoke %in% c("Fewer", "Dialy")] <- "Smoker"
eager$smoking.f <- as.factor(eager$smoking.f)
table(eager$smoking.f)

# Study name, 100-kcal variable, and fattyacid rename
eager$study <- "EAGeR"
eager$cal <- NA
eager$cal.100 <- NA
eager$fattyacid <- eager$MUFA161_serum

# Percent of women in EAGeR who had a positive pregnancy test
table(eager$pregtest)
mean(eager$pregtest)

# Distribution of vitamin D: slight right-skew
hist(eager$vitd)

# Log-odds of pregnancy across Vitamin D groups: Suggests weak positive association
logodds.graph(y = eager$pregtest, group = interval.groups(eager$vitd, 5), error.bars = "z.ci")
logodds.graph(y = eager$pregtest, group = interval.groups(eager$vitd, 10), error.bars = "z.ci")
logodds.graph(y = eager$pregtest, group = quant.groups(eager$vitd, 5), error.bars = "z.ci")
logodds.graph(y = eager$pregtest, group = quant.groups(eager$vitd, 10), error.bars = "z.ci")

# Crude assoc. for continuous vitamin D and pregnancy: Sig. positive association
tabglm(glm(pregtest ~ vitd.10, data = eager, family = "binomial"))

# Test for race-by-Vitamin D interaction
table(eager$vitd.below30)
mean(eager$vitd.below30)
tabglm(glm(pregtest ~ vitd.below20 + white + vitd.below20 * white, data = eager, family = "binomial"))
tabglm(glm(pregtest ~ vitd.below30 + white + vitd.below30 * white, data = eager, family = "binomial"))

# Create subset for white and non-white EAGER participants
sum(is.na(eager$white))
table(eager$white)
eager.white <- subset(eager, white == 1)
eager.nonwhite <- subset(eager, white == 0)

# Stratified by race: Sig. pos. assoc. in white subset (n = 1009), and larger but
# non-sig. neg. assoc. in non-white (n = 46)
tabglm(glm(pregtest ~ vitd.10, data = subset(eager, white == 1), family = "binomial"))
tabglm(glm(pregtest ~ vitd.10, data = subset(eager, white == 0), family = "binomial"))

# Race-by-Vitamin D interaction is significant (p = 0.048)
tabglm(glm(pregtest ~ white + vitd.10 + white * vitd.10, data = eager, family = "binomial"), p.decimals = 3)

# Vitamin D and pregnancy in white women. Equal-interval groups suggest increased odds of
# pregnancy in those with very high Vitamin D, but only 3-4 women in these groups. Quantile
# groups suggest fairly linear relationship. No difference in < 20 vs. >= 20, but sig. diff
# in < 30 vs. >= 30. ROC analysis favors a cut-point of 28.27. Overall, I would use it as
# continuous variable, but comparison with PSC requires binary, so may as well go with < 30.
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$vitd, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$vitd, 10), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$vitd, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$vitd, 10), error.bars = "z.ci")

logodds.graph(y = eager.white$pregtest, group = eager.white$vitd.below20, error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = eager.white$vitd.below30, error.bars = "z.ci")

tabglm(glm(pregtest ~ vitd.10, data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ poly(vitd.10, 2, raw = TRUE), data = eager.white, family = "binomial"))

# As continuous variable, association disappears when controlling for age and BMI. As < 30 vs. >= 30,
# low Vitamin D still appears harmful.
tabglm(glm(pregtest ~ age + bmi + vitd.10, data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ age + bmi + vitd.below20, data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ age + bmi + vitd.below30, data = eager.white, family = "binomial"))

eager.white$vitd.quintiles <- quant.groups(eager.white$vitd, 5)
tabglm(glm(pregtest ~ age + bmi + vitd.quintiles, data = eager.white, family = "binomial"))

roc.fit <- roc(pregtest ~ vitd, data = eager.white)
plot(roc.fit)
plot(roc.fit$thresholds, roc.fit$sensitivities, type = "p")
points(roc.fit$thresholds, roc.fit$specificities, type = "p", col = "blue")
roc.fit$thresholds[which.max(roc.fit$sensitivities + roc.fit$specificities)]

# Vitamin D and pregnancy in non-white women. Some evidence that low Vitamin D is
# associated with higher odds of pregnancy. Interestingly, association is significant
# when you control for BMI. Age is not predictive.
logodds.graph(y = eager.nonwhite$pregtest, group = interval.groups(eager.nonwhite$vitd, 5), error.bars = "z.ci")
logodds.graph(y = eager.nonwhite$pregtest, group = quant.groups(eager.nonwhite$vitd, 5), error.bars = "z.ci")

logodds.graph(y = eager.nonwhite$pregtest, group = eager.nonwhite$vitd.below20, error.bars = "z.ci")
logodds.graph(y = eager.nonwhite$pregtest, group = eager.nonwhite$vitd.below30, error.bars = "z.ci")

tabglm(glm(pregtest ~ vitd.10, data = eager.nonwhite, family = "binomial"))
tabglm(glm(pregtest ~ poly(vitd.10, 2, raw = TRUE), data = eager.nonwhite, family = "binomial"))

tabglm(glm(pregtest ~ age + bmi + vitd.10, data = eager.nonwhite, family = "binomial"))

# Age and log-odds of pregnancy: Appears roughly linear.  Could do continuous, I(30+), or 4 groups.
# Continuous seems reasonable.
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$age, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$age, 10), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$age, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$age, 10), error.bars = "z.ci")

tabglm(glm(pregtest ~ age, data = eager.white, family = "binomial"), p.decimals = 3)
tabglm(glm(pregtest ~ poly(age, 2, raw = TRUE), data = eager.white, family = "binomial"), p.decimals = 3)

tabglm(glm(pregtest ~ age.30plus, data = eager.white, family = "binomial"), p.decimals = 3)
tabglm(glm(pregtest ~ age.35plus, data = eager.white, family = "binomial"), p.decimals = 3)
tabglm(glm(pregtest ~ age.cat4, data = eager.white, family = "binomial"), p.decimals = 3)

# BMI: Data strongly supports obese vs. non-obese
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$bmi, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$bmi, 10), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$bmi, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$bmi, 10), error.bars = "z.ci")

table(eager.white$bmi.cat4)
logodds.graph(y = eager.white$pregtest, group = eager.white$bmi.cat4, error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = eager.white$bmi.cat3, error.bars = "z.ci")

# Education: Those with > HS have 29% higher odds of pregnancy (logistic reg. p = 0.25)
sum(is.na(eager.white$educ.f))
table(eager.white$educ.f)
logodds.graph(y = eager.white$pregtest, group = eager.white$educ.f, error.bars = "z.ci")
tabglm(glm(pregtest ~ educ.f, data = eager.white, family = "binomial"))

# Annual income: No association (Chi-square p = 0.12)
sum(is.na(eager.white$income.f))
table(eager.white$income.f)
logodds.graph(y = eager.white$pregtest, group = eager.white$income.f, error.bars = "z.ci")
tabglm(glm(pregtest ~ income.f, data = eager.white, family = "binomial"))

# Alcohol: No association (Chi-square p = 0.83)
sum(is.na(eager.white$alcohol.f))
table(eager.white$alcohol.f)
logodds.graph(y = eager.white$pregtest, group = eager.white$alcohol.f, error.bars = "z.ci")
tabglm(glm(pregtest ~ alcohol.f, data = eager.white, family = "binomial"))

# Smoking: No association (logistic reg. p = 0.38)
sum(is.na(eager.white$smoking.f))
table(eager.white$smoking.f)
logodds.graph(y = eager.white$pregtest, group = eager.white$smoking.f, error.bars = "z.ci")
tabglm(glm(pregtest ~ smoking.f, data = eager.white, family = "binomial"))

# MUFA161: No association. Important because it serves as D.
sum(is.na(eager.white$fattyacid))
hist(eager.white$fattyacid)
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$fattyacid, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = interval.groups(eager.white$fattyacid, 10), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$fattyacid, 5), error.bars = "z.ci")
logodds.graph(y = eager.white$pregtest, group = quant.groups(eager.white$fattyacid, 10), error.bars = "z.ci")

# Log-odds of pregnancy vs. age, obesity, and vitamin D, in white women
tabglm(glm(pregtest ~ age + obese + vitd.10, data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ age + obese + vitd.below30, data = eager.white, family = "binomial"), p.decimals = 3)

tabglm(glm(pregtest ~ age + obese + vitd.10, data = subset(eager.white, !is.na(fattyacid)), family = "binomial"), p.decimals = 3)
tabglm(glm(pregtest ~ age + obese + vitd.below30, data = subset(eager.white, !is.na(fattyacid)), family = "binomial"), p.decimals = 3)

# Further subset of those with non-missing MUFA161 (995 to 887)
dim(eager.white)
eager.premerge <- subset(eager.white, !is.na(fattyacid))
dim(eager.premerge)





# BioCycle data prep ------------------------------------------------------

# Create white vs. non-white variable
sum(is.na(biocycle$racecat3))
table(biocycle$racecat3)
biocycle$white <- ifelse(biocycle$racecat3 == 0, 1, 0)
table(biocycle$white)

# Exclude if vitamin D is missing (259 to 89, all of which are white women)
sum(is.na(biocycle$mean25OHVitDngml))
dim(biocycle)
biocycle <- subset(biocycle, !is.na(mean25OHVitDngml))
dim(biocycle)
table(biocycle$white)

# Rename vitamin D variable, and create 10-ng and "low" versions of it
biocycle$vitd <- biocycle$mean25OHVitDngml
biocycle$vitd.10 <- biocycle$vitd / 10
biocycle$vitd.below20 <- ifelse(biocycle$vitd < 20, 1, 0)
biocycle$vitd.below30 <- ifelse(biocycle$vitd < 30, 1, 0)

# Compare Vitamin D distributions in the two samples: Similar.
par(mfrow = c(2, 1))
hist(eager$vitd)
hist(biocycle$vitd)
mean(eager$vitd.below30)     # 52.0%
mean(biocycle$vitd.below30)  # 53.9%
par(mfrow = c(1, 1))

# Create age variables
sum(is.na(biocycle$screenage))
biocycle$age <- biocycle$screenage
biocycle$age.30plus <- ifelse(biocycle$age >= 30, 1, 0)
biocycle$age.35plus <- ifelse(biocycle$age >= 35, 1, 0)
biocycle$age.cat3 <- cut(biocycle$age, breaks = c(18, 30, 35, 41), include.lowest = T, right = F)
biocycle$age.cat4 <- cut(biocycle$age, breaks = c(18, 25, 30, 35, 41), include.lowest = T, right = F)
table(biocycle$age.30plus)
table(biocycle$age.35plus)
table(biocycle$age.cat3)
table(biocycle$age.cat4)

# Create BMI variables
sum(is.na(biocycle$BMI))
biocycle$bmi <- biocycle$BMI
biocycle$overweight <- ifelse(biocycle$bmi >= 25, 1, 0)
biocycle$obese <- ifelse(biocycle$bmi >= 30, 1, 0)
biocycle$bmi.cat3 <- bmi3(biocycle$bmi)
biocycle$bmi.cat4 <- bmi4(biocycle$bmi)
table(biocycle$overweight)
table(biocycle$obese)
table(biocycle$bmi.cat3)
table(biocycle$bmi.cat4)

# Education recode
sum(is.na(biocycle$highschool))
table(biocycle$highschool)
biocycle$educ.f <- factor(biocycle$highschool, levels = c(1, 0), labels = c("High school or less", "Post-secondary"))
table(biocycle$educ.f)

# Income recode
sum(is.na(biocycle$INCOME))
table(biocycle$INCOME)
biocycle$income.f <- factor(biocycle$INCOME, levels = 1: 5,
                            labels = c("(0, $20k)", "[$20k, $40k)", "[$40k, $75k)", "[$75k, $100k)", "[$100k, Inf)"))
table(biocycle$income.f)

# Alcohol intake recode
sum(is.na(biocycle$alcohol_intensity))
table(biocycle$alcohol_intensity)
biocycle$alcohol.f <- cut(biocycle$alcohol_intensity, breaks = c(0, 1, 2, 4), include.lowest = TRUE, right = FALSE,
                          labels = c("Never", "< 1x/month", ">= 1x/month"))
table(biocycle$alcohol.f)

# Smoking recode
sum(is.na(biocycle$smoker))
table(biocycle$smoker)
biocycle$smoking.f <- factor(biocycle$smoker, levels = c(0, 1), labels = c("Non-smoker", "Smoker"))
table(biocycle$smoking.f)

# Create 100-kcal variable
sum(is.na(biocycle$meanKCAL))
hist(biocycle$meanKCAL)
biocycle$cal <- biocycle$meanKCAL
biocycle$cal.100 <- biocycle$cal / 100

# Study name and fattyacid rename
biocycle$study <- "BioCycle"
sum(is.na(biocycle$MUFA161_24hdr))
hist(biocycle$MUFA161_24hdr)
biocycle$fattyacid <- biocycle$MUFA161_24hdr

# Compare MUFA161 distributions in the two samples: Much higher values in BioCycle
par(mfrow = c(2, 1))
hist(eager.premerge$fattyacid)
hist(biocycle$fattyacid)
mean(eager.premerge$fattyacid)     # 0.424
mean(biocycle$fattyacid)           # 1.043
par(mfrow = c(1, 1))


# Merge datasets ----------------------------------------------------------

# Merge EAGeR and BioCycle data
dat <- merge(eager.premerge, biocycle, all = T)
dim(eager.premerge)
dim(biocycle)
dim(dat)


# Characteristics of EAGeR vs. BioCycle --------------------------------------


# Supplementary Table 1. Characteristics of participants in EAGeR (main study)
# and BioCycle (validation study).
dim(dat)
dat$study.f <- factor(dat$study, levels = c("EAGeR", "BioCycle"))
(supptable1 <- tabmulti(dataset = dat, xvarname = "study.f",
                        yvarnames = c("age", "bmi.cat3", "educ.f", "income.f", "alcohol.f", "smoking.f"),
                        ynames = c("Age (years)", "BMI", "Education", "Income", "Alcohol intake", "Smoking status"),
                        listwise.deletion = FALSE, n.column = TRUE, n.headings = TRUE,
                        print.html = TRUE, html.filename = "supptable1.html"))



# EAGeR analysis for paper, not controlling for caloric intake ------------------------------------------------

# Number/percent who became pregnant, and who had low Vitamin D
table(eager$pregtest)
mean(eager$pregtest)
table(eager$vitd.below30)
mean(eager$vitd.below30)

# Race-by-Vitamin D interaction in 1041 women with non-missing pregnancy, age, BMI, and Vitamin D.
tabglm(glm(pregtest ~ vitd.below20 + white + vitd.below20 * white, data = eager, family = "binomial"))
tabglm(glm(pregtest ~ vitd.below30 + white + vitd.below30 * white, data = eager, family = "binomial"))
summary(glm(pregtest ~ vitd.below30 + white + vitd.below30 * white, data = eager, family = "binomial"))

tabglm(glm(pregtest ~ vitd.below30, data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ vitd.below30, data = eager.nonwhite, family = "binomial"))

tabglm(glm(pregtest ~ age + obese + vitd.below30, data = eager.white, family = "binomial"), p.decimals = 3)
tabglm(glm(pregtest ~ age + obese + vitd.below30, data = eager.nonwhite, family = "binomial"), p.decimals = 3)

tabglm(glm(pregtest ~ age + obese + vitd.below30 + white + vitd.below30 * white,
           data = eager, family = "binomial"))
tabglm(glm(pregtest ~ age + obese + vitd.10,
           data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ age + obese + vitd.below20,
           data = eager.white, family = "binomial"))
tabglm(glm(pregtest ~ age + obese + vitd.below30, data = eager.nonwhite, family = "binomial"))






# RC/ML measurement error model -------------------------------------------

# Marginal distribution of calories in BioCycle
hist(biocycle$cal.100)

# Calories vs. Vitamin D: No association.
plot(biocycle$vitd.10, biocycle$cal.100)
summary(lm(biocycle$cal.100 ~ biocycle$vitd.10))

# Calories vs. age: No association.
plot(biocycle$age, biocycle$cal.100)
summary(lm(cal.100 ~ age, data = biocycle))
means.graph(y = biocycle$cal.100, group = biocycle$age.30plus)
means.graph(y = biocycle$cal.100, group = biocycle$age.35plus)
means.graph(y = biocycle$cal.100, group = biocycle$age.cat3)
means.graph(y = biocycle$cal.100, group = biocycle$age.cat4)

# Calories vs. BMI/obesity: No association.
plot(biocycle$bmi, biocycle$cal.100)
summary(lm(cal.100 ~ bmi, data = biocycle))
means.graph(y = biocycle$cal.100, group = biocycle$overweight)
means.graph(y = biocycle$cal.100, group = biocycle$obese)
means.graph(y = biocycle$cal.100, group = biocycle$bmi.cat3)

# Calories vs. MUFA161: Strong positive association, probably secondary to measurement method
plot(biocycle$fattyacid, biocycle$cal.100)
summary(lm(biocycle$cal.100 ~ biocycle$fattyacid))
summary(lm(biocycle$cal.100 ~ poly(biocycle$fattyacid, 2, raw = TRUE)))

# Calories vs. other predictors, interaction terms, etc: Nothing there.
means.graph(y = biocycle$cal.100, group = biocycle$educ.f)
means.graph(y = biocycle$cal.100, group = biocycle$income.f)
means.graph(y = biocycle$cal.100, group = biocycle$alcohol.f)
means.graph(y = biocycle$cal.100, group = biocycle$smoking.f)

# Table 1. Linear regression fit in BioCycle (n = 89) for daily caloric
# intake (100 kcal) vs. low Vitamin D, age, obesity, and MUFA161 level.
fit <- glm(cal.100 ~ vitd.below30 + age + obese + fattyacid, data = dat)
summary(fit)
(table2 <- tabglm(glmfit = fit,
                  xlabels = c("Intercept", "Low Vitamin D", "Age", "Obese", "MUFA161"),
                  print.html = TRUE, html.filename = "table2.html"))



# RC, ML, and PSC ---------------------------------------------------------

# First, run function in ...R_package/meuc/functions/meuc_function_<date>.R.

# Create data frame with just the variables of interest
datx <- dat[, c("pregtest", "cal.100", "vitd.below30", "age", "obese", "fattyacid")]

# RC, conditional expectation view
rc1 <- rc.cond.exp(dat = datx, tdm.family = "binomial",
                   y.column = 1,
                   z.column = 2,
                   tdm.predictors = c(2, 3, 4, 5),
                   mem.predictors = c(3, 4, 5, 6))
names(rc1)
(rc1.betahats <- rc1$theta)
exp(rc1.betahats)

# RC, algebraic view
rc2 <- rc.algebraic(dat = datx, tdm.family = "binomial",
                    y.column = 1,
                    z.column = 2,
                    d.column = 6,
                    c.columns = c(3, 4, 5))
names(rc2)
(rc2.betahats <- rc2$theta[1: 5])
rc2.ors <- exp(rc2.betahats)
rc2.ses <- sqrt(diag(rc2$delta.var))[1: 5]
rc2.lower <- exp(rc2.betahats - 1.96 * rc2.ses)
rc2.upper <- exp(rc2.betahats + 1.96 * rc2.ses)

(rc2.col <- paste(sprintf("%.2f", rc2.ors), " (",
                  sprintf("%.2f", rc2.lower), "-",
                  sprintf("%.2f", rc2.upper), ")", sep = "")[-1])

# Full ML with neutral starting values (does not work!)
full.ml <- ml(dat = datx, tdm.form = "logistic",
              y.column = 1,
              z.column = 2,
              c.columns = c(3, 4, 5),
              d.columns = 6, hessian.var = F)

# Full ML, using RC estimates as starting values. Somewhat finnicky.
full.ml2 <- ml(dat = datx, tdm.form = "logistic", hessian.var = F, starting.values = c(rc2$theta, 5),
               y.column = 1,
               z.column = 2,
               c.columns = c(3, 4, 5),
               d.columns = 6)

# Try neutral starting values along with lower value for rel.tol in nlminb - get "integral is probably divergent"
full.ml2x <- ml(dat = datx, tdm.form = "logistic", hessian.var = F, nlminb.rel.tol = 1e-9,
               y.column = 1,
               z.column = 2,
               c.columns = c(3, 4, 5),
               d.columns = 6)

# Try neutral starting values, but use sigsqd value from OLS MEM fit. Works!
mem.fit <- lm(cal.100 ~ age + obese + fattyacid, data = biocycle)
sigsqd.hat <- rev(anova(mem.fit)$"Mean Sq")[1]

full.ml2x <- ml(dat = datx, tdm.form = "logistic", hessian.var = F, nlminb.rel.tol = 1e-6,
                starting.values = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, sigsqd.hat),
                y.column = 1,
                z.column = 2,
                c.columns = c(3, 4, 5),
                d.columns = 6)

# Approximate ML
approximate.ml <- ml(dat = datx, tdm.form = "logistic", probit.approximation = T, hessian.var = T,
                     y.column = 1,
                     z.column = 2,
                     c.columns = c(3, 4, 5),
                     d.columns = 6)

cbind(full.ml2$theta, approximate.ml$theta)


approximate.ml.betas <- approximate.ml$theta[1: 5]
approximate.ml.ses <- sqrt(diag(approximate.ml$hessian.var))[1: 5]
approximate.ml.lower <- exp(approximate.ml.betas - 1.96 * approximate.ml.ses)
approximate.ml.upper <- exp(approximate.ml.betas + 1.96 * approximate.ml.ses)
approximate.ml.ors <- exp(approximate.ml.betas)
approximate.ml.col <- paste(sprintf("%.2f", approximate.ml.ors), " (",
                            sprintf("%.2f", approximate.ml.lower), "-",
                            sprintf("%.2f", approximate.ml.upper), ")", sep = "")[-1]
#approximate.ml <- ml(dat = both.white, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic", probit.approximation = T,
#                     starting.values = c(rep(0, 5), mem.fit$coef, anova(mem.fit)[5, 3]), lower.values = c(rep(-Inf, 10), 0))
# approximate.ml <- ml(dat = both.white2, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic", probit.approximation = T,
#                      starting.values = c(rep(0, 5), mem.fit$coef, anova(mem.fit)[5, 3]), lower.values = c(rep(-Inf, 10), 0), hessian.var = F)

# Full ML with approximate ML starting values. Gives betax estimate of -0.327776 (0.1574518)
#full.approximate.ml <- ml(dat = both.white, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic",
#                          starting.values = approximate.ml$theta, lower.values = c(rep(-Inf, 10), 0))

# Full ML with starting values based on MEM fit.
full.ml <- ml(dat = both.white, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic",
              starting.values = c(rep(0, 5), mem.fit$coef, anova(mem.fit)[5, 3]), nlminb.trace = 1,
              lower.values = c(rep(-Inf, 10), 0.001), hessian.var = T)
full.ml
full.ml.betas <- full.ml$theta[1: 5]
full.ml.ses <- sqrt(diag(full.ml$hessian.var))[1: 5]
full.ml.lower <- exp(full.ml.betas - 1.96 * full.ml.ses)
full.ml.upper <- exp(full.ml.betas + 1.96 * full.ml.ses)
full.ml.ors <- exp(full.ml.betas)
full.ml.col <- paste(sprintf("%.2f", full.ml.ors), " (",
                     sprintf("%.2f", full.ml.lower), "-",
                     sprintf("%.2f", full.ml.upper), ")", sep = "")[-1]

# PSC, ignoring D
psc.nod <- psc(dat = both.white, tdm.family = "binomial", y.column = 1, a.column = 6, x.gs.columns = c(2, 7, 11), x.ep.columns = c(7, 11))
boots <- 1000
psc.nod.boots <- matrix(NA, ncol = 3, nrow = boots)
for (ii in 1: boots) {

  for (jj in 1: 10) {
    boot.sample <- rbind(eager.white[sample(1: nrow(eager.white), nrow(eager.white), replace = T), -1],
                         biocycle.white[sample(1: nrow(biocycle.white), nrow(biocycle.white), replace = T), -1])
    if (length(table(boot.sample$obese[888: 976])) == 2) {
      psc.nod.boots[ii, ] <- psc(dat = boot.sample, tdm.family = "binomial", y.column = 1,
                                 a.column = 6, x.gs.columns = c(2, 7, 11), x.ep.columns = c(7, 11))
      break
    }
  }

}
psc.nod.col <- c("-",
                 paste(sprintf("%.2f", exp(psc.nod[2])), " (",
                       sprintf("%.2f", exp(quantile(psc.nod.boots[, 2], probs = 0.025))), "-",
                       sprintf("%.2f", exp(quantile(psc.nod.boots[, 2], probs = 0.975))), ")", sep = ""), "-", "-")

# # PSC, including D in error-prone propensity score only
# psc.withd <- psc(dat = both.white, tdm.family = "binomial", y.column = 1, a.column = 6, x.gs.columns = c(2, 7, 11), x.ep.columns = c(3, 7, 11))
# boots <- 1000
# psc.withd.boots <- matrix(NA, ncol = 3, nrow = boots)
# for (ii in 1: boots) {
#
#   for (jj in 1: 10) {
#     boot.sample <- rbind(eager.white[sample(1: nrow(eager.white), nrow(eager.white), replace = T), -1],
#                          biocycle.white[sample(1: nrow(biocycle.white), nrow(biocycle.white), replace = T), -1])
#     if (length(table(boot.sample$obese[888: 976])) == 2) {
#       psc.withd.boots[ii, ] <- psc(dat = boot.sample, tdm.family = "binomial", y.column = 1, a.column = 6, x.gs.columns = c(2, 7, 11), x.ep.columns = c(3, 7, 11))
#       break
#     }
#   }
#
# }
# psc.withd.col <- c("-",
#                  paste(sprintf("%.2f", exp(psc.withd[2])), " (",
#                        sprintf("%.2f", exp(quantile(psc.withd.boots[, 2], probs = 0.025))), "-",
#                        sprintf("%.2f", exp(quantile(psc.withd.boots[, 2], probs = 0.975))), ")", sep = ""), "-", "-")

# Create summary table
t.eager.biocycle <- data.frame(approximate.ml.col = approximate.ml.col,
                               rc2.col = rc2.col,
                               psc.nod.col = psc.nod.col)
t.eager.biocycle <- as.matrix(t.eager.biocycle)
t.eager.biocycle <- cbind(c("Calories (100)", "Vitamin D $<$ 30 ng/ml", "Age", "Obese"), t.eager.biocycle)
colnames(t.eager.biocycle) <- c("Variable", "ML", "RC", "PSC")
t.eager.biocycle <- t.eager.biocycle[c(2, 3, 4, 1), ]
table.eager.biocycle <- xtable(t.eager.biocycle, caption = "Estimated odds ratios (95\\% CI) for incident pregnancy in EAGeR/BioCycle.",
                               label = "table_eager_biocycle")
save(table.eager.biocycle, file = "table_eager_biocycle.rda")


# Get statistics for simulations
mufa161.mean <- mean(biocycle.white$fattyacid)
mufa161.sigsq <- var(biocycle.white$fattyacid)
range(eager.white$age)
table(eager.white$obese)
summary(glm(vitd.below30 ~ fattyacid + age + obese, data = both.white, family = "binomial"))
approximate.ml






# ML with "smarter" starting values
starting.values <- c(rc.est1, anova(mem.fit)[5, 3])
lower.values <- c(rep(-Inf, 10), 0)
fixed.values <- c(rep(NA, 5), fitx$coef, anova(fitx)[5, 3])
ml.est <- ml(dat = both.white, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic", fixed.values = fixed.values)

ml.est <- ml(dat = both.white, y.column = 1, z.column = 2, c.columns = c(6, 7, 11), d.columns = 3, tdm.form = "logistic",
             starting.values = starting.values, lower.values = lower.values, fixed.values = fixed.values)

both.complete$low.vitd <- ifelse(both.complete$vitd.10 < 2, 1, 0)
table(both.complete$low.vitd)
psc.est <- psc(dat = both.complete, y.column = 1, a.column = 10, x.gs.columns = c(2, 5, 6), x.ep.columns = c(5, 6), tdm.family = "binomial")
psc.est

both.complete.subset <- rbind(eager.sub.complete[1:100, ], biocycle.sub.complete)
both.complete.subset <- both.complete.subset[, -1]
ml.est <- ml(dat = both.complete.subset, y.column = 1, z.column = 2, c.columns = c(5, 6, 4), d.columns = 3, tdm.form = "logistic", nlminb.rel.tol = 1e-5)
rc.est <- rc.cond.exp(dat = both.complete.subset, y.column = 1, z.column = 2, tdm.predictors = c(4, 5, 6), mem.predictors = c(4, 5, 6, 3), tdm.family = "binomial")
rc.est
psc.est <- psc(dat = both.complete.subset, )





# Age and BMI
summary(glm(pregtest ~ age + BMI + white + vitd.10 + white*vitd.10, data = eager.nowd, family = "binomial"))
summary(glm(pregtest ~ age + BMI + vitd.10, data = subset(eager.nowd, white == 0), family = "binomial"))
summary(glm(pregtest ~ age + BMI + vitd.10, data = subset(eager.nowd, white == 1), family = "binomial"))


summary(glm(pregtest ~ white + vitd.10 + white * vitd.10, data = eager.nowd, family = "binomial"))
summary(glm(pregtest ~ vitd.10, data = subset(eager.nowd, white == 1), family = "binomial"))
summary(glm(pregtest ~ vitd.10, data = subset(eager.nowd, white == 0), family = "binomial"))
summary(glm(pregtest ~ age + weight + vitd.10, data = subset(eager.nowd, white == 1), family = "binomial"))
summary(glm(pregtest ~ age + weight + vitd.10, data = subset(eager.nowd, white == 0), family = "binomial"))

# Try "low vitamin D" variable
eager.nowd$low.d <- ifelse(eager.nowd$vitd.10 < 20, 1, 0)
summary(glm(pregtest ~ low.d, data = eager.nowd, family = "binomial"))
summary(glm(pregtest ~ age + weight + low.d, data = eager.nowd, family = "binomial"))

summary(glm(pregtest ~ low.d, data = subset(eager.nowd, white == 0), family = "binomial"))
summary(glm(pregtest ~ low.d, data = subset(eager.nowd, white == 1), family = "binomial"))

summary(glm(pregtest ~ age + weight + low.d, data = subset(eager.nowd, white == 0), family = "binomial"))
summary(glm(pregtest ~ age + weight + low.d, data = subset(eager.nowd, white == 1), family = "binomial"))

summary(fit)

head(eager)
head(biocycle)


